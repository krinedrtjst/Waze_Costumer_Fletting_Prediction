{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"colab":{"provenance":[{"file_id":"1DHsmIEwaXUmfVT4tFzyOwyyfXAX0v6IF","timestamp":1681833478247},{"file_id":"1oNheYh5WbljxkvoK_BMkQTey2DWnFXMs","timestamp":1674856595373}]},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":6474252,"sourceType":"datasetVersion","datasetId":3739866},{"sourceId":7666084,"sourceType":"datasetVersion","datasetId":4470785},{"sourceId":9111137,"sourceType":"datasetVersion","datasetId":5499152}],"dockerImageVersionId":30746,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# **Machine Learning Model on Waze Data** \n","metadata":{"id":"DtNBZFHO3M7n"}},{"cell_type":"markdown","source":"The primary objective of this project is to build a Machine Learning Model to analyze Waze's data and identify the patterns who forwarded of users that churn, and increase retention of those who stayed, thus boost the app's growth for those who continue to use the platform. \n\nWith this model we aimed to understand the flow of employee terminations and retention, as well as the softer nuances that led to their dissatisfaction in the organizational environment.\n\nThe Ethical considerations of this project  don't offer harms to organization, thus not impacting on business operations, the ostracization of groups of people, large-scale harms to system such as to financial systems. \n\nThe implications of misguided forecasts are when it predicts a false negative, leading the model says a Waze user won't churn, but they actually will. The impact of these suggestions on the user's routine may involve Waze might proactively push an app notification to users, or send a survey to better understand user dissatisfaction. \n\nWhen the model predicts a false negative, driving in resultsb that says a Waze user will churn, but they actually won't, the impact of these suggestions on the user's relationship may lead to take proactive measures and this can add to an annoying or negative experience for loyal users of the app.\n\nThe benefits of the model proposed here outweigh all the obstacles listed and add up to a reduction in the company's costs. \n\nThe proactive measures implemented by Waze could potentially have unintended consequences on users, possibly leading to user churn. It is advisable to conduct follow-up analyses to evaluate the effectiveness of these measures. If these measures prove to be reasonable and effective, the benefits will likely surpass any issues that arise.\n\n\n\n\n\n\n","metadata":{"id":"XfCZ5KuI_2lT"}},{"cell_type":"markdown","source":"### Imports and Data Loading\n\nImport the packages necessary and the libraries needed to build and evaluate random forest and XGBoost classification models.","metadata":{"id":"e8Vm3QEfGELS"}},{"cell_type":"code","source":"# Import packages for data manipulation\nimport numpy as np\nimport pandas as pd\n\n# Import packages for data visualization\nimport matplotlib.pyplot as plt\n\n# This lets us see all of the columns, preventing Juptyer from redacting them.\npd.set_option('display.max_columns', None)\n\n# Import packages for data modeling\nfrom sklearn.model_selection import GridSearchCV, train_test_split\nfrom sklearn.metrics import roc_auc_score, roc_curve, auc\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score,\\\nf1_score, confusion_matrix, ConfusionMatrixDisplay, RocCurveDisplay, PrecisionRecallDisplay\n\nfrom sklearn.ensemble import RandomForestClassifier\nfrom xgboost import XGBClassifier\n\n# This is the function that helps plot feature importance\nfrom xgboost import plot_importance\n\n# This module lets us save our models once we fit them.\nimport pickle\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")\npd.set_option('display.max_columns',None)\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","metadata":{"id":"fKhnX2Puf4Bt","trusted":true,"execution":{"iopub.status.busy":"2025-09-02T17:34:38.743664Z","iopub.status.idle":"2025-09-02T17:34:38.744046Z","shell.execute_reply.started":"2025-09-02T17:34:38.743879Z","shell.execute_reply":"2025-09-02T17:34:38.743893Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Now we gonna read in the dataset as `df0` and inspect the first five rows.","metadata":{"id":"IeXTZ2tdbALL"}},{"cell_type":"code","source":"# Import dataset\ndf0 = pd.read_csv(\"/kaggle/input/waze-dataset-to-predict-user-churn/waze_dataset.csv\")","metadata":{"id":"5weTXGKqa_iG","trusted":true,"execution":{"iopub.status.busy":"2025-09-02T17:34:38.745609Z","iopub.status.idle":"2025-09-02T17:34:38.746129Z","shell.execute_reply.started":"2025-09-02T17:34:38.745879Z","shell.execute_reply":"2025-09-02T17:34:38.745900Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Inspect the first five rows\ndf0.head()","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":270},"executionInfo":{"elapsed":5,"status":"ok","timestamp":1685765621766,"user":{"displayName":"Matteo Riotto","userId":"15211004813978485634"},"user_tz":420},"id":"t9u3R4HuFQIZ","outputId":"e31e9fe2-d641-41d6-ac62-350062762256","trusted":true,"execution":{"iopub.status.busy":"2025-09-02T17:34:38.748124Z","iopub.status.idle":"2025-09-02T17:34:38.748623Z","shell.execute_reply.started":"2025-09-02T17:34:38.748381Z","shell.execute_reply":"2025-09-02T17:34:38.748401Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### **Feature Engineering**\n\nWe prepared this data and performed exploratory data analysis (EDA) in previous courses. You know that some features had stronger correlations with churn than others, and you also created some features that may be useful.\n\nIn this part of the project, you'll engineer these features and some new features to use for modeling.\n\nTo begin, create a copy of `df0` to preserve the original dataframe. Call the copy `df`.","metadata":{"id":"5VZowX9rhU1o"}},{"cell_type":"code","source":"# Copy the df0 dataframe\ndf = df0.copy()","metadata":{"id":"ZJsPbbPFMQe1","trusted":true,"execution":{"iopub.status.busy":"2025-09-02T17:34:38.750190Z","iopub.status.idle":"2025-09-02T17:34:38.750545Z","shell.execute_reply.started":"2025-09-02T17:34:38.750383Z","shell.execute_reply":"2025-09-02T17:34:38.750397Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Call `info()` on the new dataframe so the existing columns can be easily referenced.","metadata":{"id":"oXJIPB9sMIpa"}},{"cell_type":"code","source":"df.info()","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3,"status":"ok","timestamp":1685765626095,"user":{"displayName":"Matteo Riotto","userId":"15211004813978485634"},"user_tz":420},"id":"mBOSW8IDbO_d","outputId":"b543ff3a-9e18-474d-a0cb-8ff9c5306235","trusted":true,"execution":{"iopub.status.busy":"2025-09-02T17:34:38.752099Z","iopub.status.idle":"2025-09-02T17:34:38.752442Z","shell.execute_reply.started":"2025-09-02T17:34:38.752283Z","shell.execute_reply":"2025-09-02T17:34:38.752297Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"#### **`km_per_driving_day`**\n\n1. Create a feature representing the mean number of kilometers driven on each driving day in the last month for each user. Add this feature as a column to `df`.\n\n2. Get descriptive statistics for this new feature","metadata":{"id":"zA8NHyLDIpeT"}},{"cell_type":"code","source":"# 1. Create `km_per_driving_day` feature\ndf['km_per_driving_day'] = df['driven_km_drives'] / df['driving_days']\n\n# 2. Get descriptive stats\ndf['km_per_driving_day'].describe()","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":300,"status":"ok","timestamp":1685765628722,"user":{"displayName":"Matteo Riotto","userId":"15211004813978485634"},"user_tz":420},"id":"PzqACNPlIMFi","outputId":"4502cb7b-c9fd-4407-c40f-e33f9556ceae","trusted":true,"execution":{"iopub.status.busy":"2025-09-02T17:34:38.753478Z","iopub.status.idle":"2025-09-02T17:34:38.753858Z","shell.execute_reply.started":"2025-09-02T17:34:38.753658Z","shell.execute_reply":"2025-09-02T17:34:38.753672Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"We notice that some values are infinite. This is the result of there being values of zero in the `driving_days` column. Pandas imputes a value of infinity in the corresponding rows of the new column because division by zero is undefined. We gonna follow two steps in this case:\n\n1. Convert these values from infinity to zero. Using `np.inf` to refer to a value of infinity.\n\n2. Call `describe()` on the `km_per_driving_day` column to verify that it worked.","metadata":{"id":"uhw6SnOHuEoz"}},{"cell_type":"code","source":"# 1. Convert infinite values to zero\ndf.loc[df['km_per_driving_day']==np.inf, 'km_per_driving_day'] = 0\n\n# 2. Confirm that it worked\ndf['km_per_driving_day'].describe()","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3,"status":"ok","timestamp":1685765630162,"user":{"displayName":"Matteo Riotto","userId":"15211004813978485634"},"user_tz":420},"id":"pl_hHhfauh00","outputId":"51f5522c-f95a-4df5-e781-133c1578893e","trusted":true,"execution":{"iopub.status.busy":"2025-09-02T17:34:38.755559Z","iopub.status.idle":"2025-09-02T17:34:38.756058Z","shell.execute_reply.started":"2025-09-02T17:34:38.755813Z","shell.execute_reply":"2025-09-02T17:34:38.755834Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"#### **`percent_sessions_in_last_month`**\n\n1. Create a new column `percent_sessions_in_last_month` that represents the percentage of each user's total sessions that were logged in their last month of use.\n\n2. Get descriptive statistics for this new feature","metadata":{"id":"-vZMI319M5ER"}},{"cell_type":"code","source":"# 1. Create `percent_sessions_in_last_month` feature\ndf['percent_sessions_in_last_month'] = df['sessions'] / df['total_sessions']\n\n# 2. Get descriptive stats\ndf['percent_sessions_in_last_month'].describe()","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6,"status":"ok","timestamp":1685765631845,"user":{"displayName":"Matteo Riotto","userId":"15211004813978485634"},"user_tz":420},"id":"ZvT74d1EIMDo","outputId":"e1d1fbdf-c542-44b5-9af5-2233e034d6af","trusted":true,"execution":{"iopub.status.busy":"2025-09-02T17:34:38.757088Z","iopub.status.idle":"2025-09-02T17:34:38.757546Z","shell.execute_reply.started":"2025-09-02T17:34:38.757319Z","shell.execute_reply":"2025-09-02T17:34:38.757338Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"#### **`professional_driver`**\n\nThe objective now in data modeling is to create a new feature that separates professional drivers from other drivers. In this scenario, domain knowledge and intuition are used to determine these deciding thresholds, but ultimately they are arbitrary.\n\nCreate a new, binary feature called `professional_driver` that is a 1 for users who had 60 or more drives <u>**and**</u> drove on 15+ days in the last month.\n","metadata":{"id":"XP5xpoWqNbUC"}},{"cell_type":"markdown","source":"To create this column, use the [`np.where()`](https://numpy.org/doc/stable/reference/generated/numpy.where.html) function. This function accepts as arguments:\n1. A condition\n2. What to return when the condition is true\n3. What to return when the condition is false\n\n```\nExample:\nx = [1, 2, 3]\nx = np.where(x > 2, 100, 0)\nx\narray([  0,   0, 100])\n```","metadata":{"id":"I77Q_UpJNrwr"}},{"cell_type":"code","source":"# Create `professional_driver` feature\ndf['professional_driver'] = np.where((df['drives'] >= 60) & (df['driving_days'] >= 15), 1, 0)","metadata":{"id":"ZNmJdqJWIMBi","trusted":true,"execution":{"iopub.status.busy":"2025-09-02T17:34:38.759744Z","iopub.status.idle":"2025-09-02T17:34:38.760234Z","shell.execute_reply.started":"2025-09-02T17:34:38.759982Z","shell.execute_reply":"2025-09-02T17:34:38.760003Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"#### **`total_sessions_per_day`**\n\nNow, we create a new column that represents the mean number of sessions per day _since onboarding_.","metadata":{"id":"D6Rz587QOCUN"}},{"cell_type":"code","source":"# Create `total_sessions_per_day` feature\ndf['total_sessions_per_day'] = df['total_sessions'] / df['n_days_after_onboarding']","metadata":{"id":"NTlzoBQqNaaZ","trusted":true,"execution":{"iopub.status.busy":"2025-09-02T17:34:38.761530Z","iopub.status.idle":"2025-09-02T17:34:38.762026Z","shell.execute_reply.started":"2025-09-02T17:34:38.761782Z","shell.execute_reply":"2025-09-02T17:34:38.761802Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"As with other features, get descriptive statistics for this new feature.","metadata":{"id":"8Ur8YjBUvC7I"}},{"cell_type":"code","source":"# Get descriptive stats\ndf['total_sessions_per_day'].describe()","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":407,"status":"ok","timestamp":1685765644809,"user":{"displayName":"Matteo Riotto","userId":"15211004813978485634"},"user_tz":420},"id":"QZlkvYzJvUXu","outputId":"8a8e5c3a-5c20-407e-8bf3-d03db79f8ead","trusted":true,"execution":{"iopub.status.busy":"2025-09-02T17:34:38.763910Z","iopub.status.idle":"2025-09-02T17:34:38.764307Z","shell.execute_reply.started":"2025-09-02T17:34:38.764140Z","shell.execute_reply":"2025-09-02T17:34:38.764154Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"#### **`km_per_hour`**\n\nCreate a column representing the mean kilometers per hour driven in the last month.","metadata":{"id":"wlIGrAfTPr1T"}},{"cell_type":"code","source":"# Create `km_per_hour` feature\ndf['km_per_hour'] = df['driven_km_drives'] / df['duration_minutes_drives'] / 60\ndf['km_per_hour'].describe()","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":310,"status":"ok","timestamp":1685765646463,"user":{"displayName":"Matteo Riotto","userId":"15211004813978485634"},"user_tz":420},"id":"BCo9ddW0P2rm","outputId":"2d749be4-d14a-4720-932d-25e0daad9975","trusted":true,"execution":{"iopub.status.busy":"2025-09-02T17:34:38.765516Z","iopub.status.idle":"2025-09-02T17:34:38.765872Z","shell.execute_reply.started":"2025-09-02T17:34:38.765677Z","shell.execute_reply":"2025-09-02T17:34:38.765713Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"#### **`km_per_drive`**\n\nCreate a column representing the mean number of kilometers per drive made in the last month for each user. Then, print descriptive statistics for the feature.","metadata":{"id":"VnFLfrleQat0"}},{"cell_type":"code","source":"# Create `km_per_drive` feature\ndf['km_per_drive'] = df['driven_km_drives'] / df['drives']\ndf['km_per_drive'].describe()","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":287,"status":"ok","timestamp":1685765649546,"user":{"displayName":"Matteo Riotto","userId":"15211004813978485634"},"user_tz":420},"id":"qP-lBOZtQKH1","outputId":"7f655917-91d9-4667-ebb9-871bdd04120b","trusted":true,"execution":{"iopub.status.busy":"2025-09-02T17:34:38.767441Z","iopub.status.idle":"2025-09-02T17:34:38.767936Z","shell.execute_reply.started":"2025-09-02T17:34:38.767672Z","shell.execute_reply":"2025-09-02T17:34:38.767712Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"This feature has infinite values too. We gonna do same as the data above and convert the infinite values to zero.\n\n","metadata":{"id":"bCEOcKJd1NnI"}},{"cell_type":"code","source":"# 1. Convert infinite values to zero\ndf.loc[df['km_per_drive']==np.inf, 'km_per_drive'] = 0\n\n# 2. Confirm that it worked\ndf['km_per_drive'].describe()","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":275,"status":"ok","timestamp":1685765656668,"user":{"displayName":"Matteo Riotto","userId":"15211004813978485634"},"user_tz":420},"id":"HI0h4g2N1aE9","outputId":"f4771080-1e29-4a96-97b2-750016ac3767","trusted":true,"execution":{"iopub.status.busy":"2025-09-02T17:34:38.769093Z","iopub.status.idle":"2025-09-02T17:34:38.769566Z","shell.execute_reply.started":"2025-09-02T17:34:38.769331Z","shell.execute_reply":"2025-09-02T17:34:38.769350Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"#### **`percent_of_sessions_to_favorite`**\n\nIn this modeling, we will create a new column that represents the percentage of total sessions used to navigate to one of the users' favorite places.\n\nThis serves as a proxy for the percentage of overall drives to a favorite place. Since the total drives since onboarding are not included in this dataset, total sessions must serve as a reasonable approximation.\n\nPeople whose drives to non-favorite places make up a higher percentage of their total drives might be less likely to churn, as they are making more trips to less familiar places.","metadata":{"id":"QhvumW3dRLVw"}},{"cell_type":"code","source":"# Create `percent_of_sessions_to_favorite` feature\ndf['percent_of_drives_to_favorite'] = (\n    df['total_navigations_fav1'] + df['total_navigations_fav2']) / df['total_sessions']\n\n# Get descriptive stats\ndf['percent_of_drives_to_favorite'].describe()","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":248,"status":"ok","timestamp":1685765660401,"user":{"displayName":"Matteo Riotto","userId":"15211004813978485634"},"user_tz":420},"id":"3VQvevYeRK0u","outputId":"63b0de1d-c30a-4485-acc2-de4797896dd7","trusted":true,"execution":{"iopub.status.busy":"2025-09-02T17:34:38.771880Z","iopub.status.idle":"2025-09-02T17:34:38.772198Z","shell.execute_reply.started":"2025-09-02T17:34:38.772049Z","shell.execute_reply":"2025-09-02T17:34:38.772061Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### **Droping Missing Values**\nBased on previous exploratory data analysis (EDA), there is no evidence of a non-random cause for the 700 missing values in the label column. Since these missing values account for less than 5% of the dataset, we will use the dropna() method to remove the rows with this missing data. ","metadata":{"id":"gZ0zDWmsTeOA"}},{"cell_type":"code","source":"# Droped rows with missing values\ndf = df.dropna(subset=['label'])","metadata":{"id":"teUeCF-yf_6o","trusted":true,"execution":{"iopub.status.busy":"2025-09-02T17:34:38.773550Z","iopub.status.idle":"2025-09-02T17:34:38.773906Z","shell.execute_reply.started":"2025-09-02T17:34:38.773745Z","shell.execute_reply":"2025-09-02T17:34:38.773760Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### **Variable Encoding**","metadata":{"id":"uFnVVQ_OTpqz"}},{"cell_type":"markdown","source":"#### **Dummying features**\n\nIn order to use `device` as an X variable, you will need to convert it to binary, since this variable is categorical.\n\nIn cases where the data contains many categorical variables, you can use pandas built-in [`pd.get_dummies()`](https://pandas.pydata.org/docs/reference/api/pandas.get_dummies.html), or you can use scikit-learn's [`OneHotEncoder()`](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.OneHotEncoder.html) function.\n\n**Note:** Each possible category of each feature will result in a feature for your model, which could lead to an inadequate ratio of features to observations and/or difficulty understanding your model's predictions.\n\nBecause this dataset only has one remaining categorical feature (`device`), it's not necessary to use one of these special functions. You can just implement the transformation directly.\n\nWe gonna create a new binary column called `device2` that encodes user devices as follows:\n\n* `Android` -> `0`\n* `iPhone` -> `1`","metadata":{"id":"o3ArC_5xa7Oi"}},{"cell_type":"code","source":"# Create new `device2` variable\ndf['device2'] = np.where(df['device']=='Android', 0, 1)\ndf[['device', 'device2']].tail()","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":206},"executionInfo":{"elapsed":304,"status":"ok","timestamp":1685765686284,"user":{"displayName":"Matteo Riotto","userId":"15211004813978485634"},"user_tz":420},"id":"QvDpwcQm0f35","outputId":"f4f36452-731a-403d-e109-a02df1520db7","trusted":true,"execution":{"iopub.status.busy":"2025-09-02T17:34:38.775352Z","iopub.status.idle":"2025-09-02T17:34:38.775717Z","shell.execute_reply.started":"2025-09-02T17:34:38.775536Z","shell.execute_reply":"2025-09-02T17:34:38.775550Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"#### **Target Encoding**\n\nThe target variable is also categorical, since a user is labeled as either \"churned\" or \"retained.\" Change the data type of the `label` column to be binary. This change is needed to train the models.\n\nAssign a `0` for all `retained` users.\n\nAssign a `1` for all `churned` users.\n\nSave this variable as `label2` so as not to overwrite the original `label` variable.\n","metadata":{"id":"UV3KLq7LpcWB"}},{"cell_type":"code","source":"# Create binary `label2` column\ndf['label2'] = np.where(df['label']=='churned', 1, 0)\ndf[['label', 'label2']].tail()","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":206},"executionInfo":{"elapsed":291,"status":"ok","timestamp":1685765692665,"user":{"displayName":"Matteo Riotto","userId":"15211004813978485634"},"user_tz":420},"id":"7fRaU2JKpyXg","outputId":"05eb3516-2c5f-44b3-b453-8a3fcdec8941","trusted":true,"execution":{"iopub.status.busy":"2025-09-02T17:34:38.777214Z","iopub.status.idle":"2025-09-02T17:34:38.777568Z","shell.execute_reply.started":"2025-09-02T17:34:38.777407Z","shell.execute_reply":"2025-09-02T17:34:38.777422Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### **Feature Selection**\n\nTree-based models can handle multicollinearity, so the only feature that can be cut is `ID`, since it doesn't contain any information relevant to churn.\n\nNote, however, that `device` won't be used simply because it's a copy of `device2`.\n\nDrop `ID` from the `df` dataframe.","metadata":{"id":"MSqM4oiyuuzw"}},{"cell_type":"code","source":"# Drop `ID` column\ndf = df.drop(['ID'], axis=1)","metadata":{"id":"vv3owriWuuDQ","trusted":true,"execution":{"iopub.status.busy":"2025-09-02T17:34:38.778747Z","iopub.status.idle":"2025-09-02T17:34:38.779059Z","shell.execute_reply.started":"2025-09-02T17:34:38.778913Z","shell.execute_reply":"2025-09-02T17:34:38.778925Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### **Evaluation Metric**\n\nWe gonna examine the class balance of your target variable to ecide on an evaluation metric. This will depend on the class balance of the target variable and the use case of the model.","metadata":{"id":"nZfNE37b-LlJ"}},{"cell_type":"code","source":"# Get class balance of 'label' col\ndf['label'].value_counts(normalize=True)","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":254,"status":"ok","timestamp":1685765707119,"user":{"displayName":"Matteo Riotto","userId":"15211004813978485634"},"user_tz":420},"id":"4mRefXCF-K_c","outputId":"4a0f5d9c-cd7a-4548-d607-5388d68c906e","trusted":true,"execution":{"iopub.status.busy":"2025-09-02T17:34:38.780163Z","iopub.status.idle":"2025-09-02T17:34:38.780488Z","shell.execute_reply.started":"2025-09-02T17:34:38.780325Z","shell.execute_reply":"2025-09-02T17:34:38.780338Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Approximately 18% of the users in this dataset churned. This is an unbalanced dataset, but not extremely so. It can be modeled without any class rebalancing.\n\nConsider which evaluation metric is best. Remember, accuracy might not be the best gauge of performance because a model can have high accuracy on an imbalanced dataset and still fail to predict the minority class.\n\nIt was already determined that the risks involved in making a false positive prediction are minimal. No one stands to get hurt, lose money, or suffer any other significant consequence if they are predicted to churn. Therefore, on this project we gonna select the model based on the recall score.","metadata":{"id":"jRehfuoyi6I2"}},{"cell_type":"markdown","source":"### **Model Selection Process and Modeling Workflow**\n\nThe final modeling dataset contains 14,299 samples. This is towards the lower end of what might be considered sufficient to conduct a robust model selection process, but still doable.The next steps are:\n\n1. Split the data into train/validation/test sets (60/20/20)\n\nNote that, when deciding the split ratio and whether or not to use a validation set to select a champion model, consider both how many samples will be in each data partition, and how many examples of the minority class each would therefore contain. In this case, a 60/20/20 split would result in \\~2,860 samples in the validation set and the same number in the test set, of which \\~18%&mdash;or 515 samples&mdash;would represent users who churn.\n\n2. Fit models and tune hyperparameters on the training set\n\n3. Perform final model selection on the validation set\n\n4. Assess the champion model's performance on the test set\n\n![](https://raw.githubusercontent.com/adacert/tiktok/main/optimal_model_flow_numbered.svg)","metadata":{"id":"G5jzGjOS8iiv"}},{"cell_type":"markdown","source":"### **Split the Data**\n\nThe only remaining step to model the data step is to split the data into features/target variable and training/validation/test sets.\n\n1. Define a variable `X` that isolates the features. Remember not to use `device`.\n\n2. Define a variable `y` that isolates the target variable (`label2`).\n\n3. Split the data 80/20 into an interim training set and a test set. Don't forget to stratify the splits, and set the random state to 42.\n\n4. Split the interim training set 75/25 into a training set and a validation set, yielding a final ratio of 60/20/20 for training/validation/test sets. Again, don't forget to stratify the splits and set the random state.","metadata":{"id":"Nx41bVxX89Fe"}},{"cell_type":"code","source":"# 1. Isolate X variables\nX = df.drop(columns=['label', 'label2', 'device'])\n\n# 2. Isolate y variable\ny = df['label2']\n\n# 3. Split into train and test sets\nX_tr, X_test, y_tr, y_test = train_test_split(X, y, stratify=y,\n                                              test_size=0.2, random_state=42)\n\n# 4. Split into train and validate sets\nX_train, X_val, y_train, y_val = train_test_split(X_tr, y_tr, stratify=y_tr,\n                                                  test_size=0.25, random_state=42)","metadata":{"id":"qLbapbSWDUL-","trusted":true,"execution":{"iopub.status.busy":"2025-09-02T17:34:38.782666Z","iopub.status.idle":"2025-09-02T17:34:38.783197Z","shell.execute_reply.started":"2025-09-02T17:34:38.782943Z","shell.execute_reply":"2025-09-02T17:34:38.782964Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Verify the number of samples in the partitioned data.","metadata":{"id":"ZNQ5UCwtqsEC"}},{"cell_type":"code","source":"for x in [X_train, X_val, X_test]:\n    print(len(x))","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3,"status":"ok","timestamp":1685765715636,"user":{"displayName":"Matteo Riotto","userId":"15211004813978485634"},"user_tz":420},"id":"QmUF9qGdq3RO","outputId":"f971e6b3-1b47-4f5a-8564-693091b5acbb","trusted":true,"execution":{"iopub.status.busy":"2025-09-02T17:34:38.784748Z","iopub.status.idle":"2025-09-02T17:34:38.785244Z","shell.execute_reply.started":"2025-09-02T17:34:38.784984Z","shell.execute_reply":"2025-09-02T17:34:38.785005Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"This aligns with expectations of the samples.","metadata":{"id":"e2oQFKBcsYIt"}},{"cell_type":"markdown","source":"### **Modeling**","metadata":{"id":"fCHCDdW3swPj"}},{"cell_type":"markdown","source":"#### **Random Forest**\n\nUsing `GridSearchCV` to tune a random forest model and follow those steps:\n\n1. Instantiate the random forest classifier `rf` and set the random state.\n\n2. Create a dictionary `cv_params` of any of the following hyperparameters and their corresponding values to tune. The more you tune, the better your model will fit the data, but the longer it will take.\n - `max_depth`\n - `max_features`\n - `max_samples`\n - `min_samples_leaf`\n - `min_samples_split`\n - `n_estimators`\n\n3. Define a dictionary `scoring` of scoring metrics for GridSearch to capture (precision, recall, F1 score, and accuracy).\n\n4. Instantiate the `GridSearchCV` object `rf_cv`. Pass to it as arguments:\n - estimator=`rf`\n - param_grid=`cv_params`\n - scoring=`scoring`\n - cv: define the number of cross-validation folds you want (`cv=_`)\n - refit: indicate which evaluation metric you want to use to select the model (`refit=_`)\n\n `refit` should be set to `'recall'`.<font/>\n","metadata":{"id":"vynZs5het1b_"}},{"cell_type":"code","source":"# 1. Instantiate the random forest classifier\nrf = RandomForestClassifier(random_state=42)\n\n# 2. Create a dictionary of hyperparameters to tune\ncv_params = {'max_depth': [None],\n             'max_features': [1.0],\n             'max_samples': [1.0],\n             'min_samples_leaf': [2],\n             'min_samples_split': [2],\n             'n_estimators': [300],\n             }\n\n# 3. Define a dictionary of scoring metrics to capture\nscoring = {'accuracy', 'precision', 'recall', 'f1'}\n\n# 4. Instantiate the GridSearchCV object\nrf_cv = GridSearchCV(rf, cv_params, scoring=scoring, cv=4, refit='recall')","metadata":{"id":"Vj5rJWOv5O3d","trusted":true,"execution":{"iopub.status.busy":"2025-09-02T17:34:38.787080Z","iopub.status.idle":"2025-09-02T17:34:38.787602Z","shell.execute_reply.started":"2025-09-02T17:34:38.787354Z","shell.execute_reply":"2025-09-02T17:34:38.787375Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Now fit the model to the training data.","metadata":{"id":"Wv_WvRA1RqTl"}},{"cell_type":"code","source":"%%time\nrf_cv.fit(X_train, y_train)","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":152},"executionInfo":{"elapsed":119330,"status":"ok","timestamp":1685765843795,"user":{"displayName":"Matteo Riotto","userId":"15211004813978485634"},"user_tz":420},"id":"OXuBiTGi5ZHn","outputId":"d3cc06bc-a926-4154-fa37-38a8abc2cf78","trusted":true,"execution":{"iopub.status.busy":"2025-09-02T17:34:38.788974Z","iopub.status.idle":"2025-09-02T17:34:38.789465Z","shell.execute_reply.started":"2025-09-02T17:34:38.789212Z","shell.execute_reply":"2025-09-02T17:34:38.789241Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Examine the best average score across all the validation folds.","metadata":{"id":"QIaRiZW4hf-6"}},{"cell_type":"code","source":"# Examine best score\nrf_cv.best_score_","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":252,"status":"ok","timestamp":1685765857251,"user":{"displayName":"Matteo Riotto","userId":"15211004813978485634"},"user_tz":420},"id":"29kGUegqhviL","outputId":"4d8f983e-56c5-4972-e346-f4fc1d8abf7f","trusted":true,"execution":{"iopub.status.busy":"2025-09-02T17:34:38.790512Z","iopub.status.idle":"2025-09-02T17:34:38.791012Z","shell.execute_reply.started":"2025-09-02T17:34:38.790767Z","shell.execute_reply":"2025-09-02T17:34:38.790787Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Examine the best combination of hyperparameters.","metadata":{"id":"heGb51fHh3E5"}},{"cell_type":"code","source":"# Examine best hyperparameter combo\nrf_cv.best_params_","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":262,"status":"ok","timestamp":1685765859250,"user":{"displayName":"Matteo Riotto","userId":"15211004813978485634"},"user_tz":420},"id":"FjgXbO7Kh8is","outputId":"71f45fbc-3809-4c52-f381-1b7ff28485fb","trusted":true,"execution":{"iopub.status.busy":"2025-09-02T17:34:38.793065Z","iopub.status.idle":"2025-09-02T17:34:38.793549Z","shell.execute_reply.started":"2025-09-02T17:34:38.793308Z","shell.execute_reply":"2025-09-02T17:34:38.793328Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Use the `make_results()` function to output all of the scores of your model. Note that the function accepts three arguments.","metadata":{"id":"qZZnem5yiAau"}},{"cell_type":"code","source":"def make_results(model_name:str, model_object, metric:str):\n    '''\n    Arguments:\n        model_name (string): what you want the model to be called in the output table\n        model_object: a fit GridSearchCV object\n        metric (string): precision, recall, f1, or accuracy\n\n    Returns a pandas df with the F1, recall, precision, and accuracy scores\n    for the model with the best mean 'metric' score across all validation folds.\n    '''\n\n    # Create dictionary that maps input metric to actual metric name in GridSearchCV\n    metric_dict = {'precision': 'mean_test_precision',\n                   'recall': 'mean_test_recall',\n                   'f1': 'mean_test_f1',\n                   'accuracy': 'mean_test_accuracy',\n                   }\n\n    # Get all the results from the CV and put them in a df\n    cv_results = pd.DataFrame(model_object.cv_results_)\n\n    # Isolate the row of the df with the max(metric) score\n    best_estimator_results = cv_results.iloc[cv_results[metric_dict[metric]].idxmax(), :]\n\n    # Extract accuracy, precision, recall, and f1 score from that row\n    f1 = best_estimator_results.mean_test_f1\n    recall = best_estimator_results.mean_test_recall\n    precision = best_estimator_results.mean_test_precision\n    accuracy = best_estimator_results.mean_test_accuracy\n\n    # Create table of results\n    table = pd.DataFrame({'model': [model_name],\n                          'precision': [precision],\n                          'recall': [recall],\n                          'F1': [f1],\n                          'accuracy': [accuracy],\n                          },\n                         )\n\n    return table","metadata":{"id":"u-UodWEOedxz","trusted":true,"execution":{"iopub.status.busy":"2025-09-02T17:34:38.795257Z","iopub.status.idle":"2025-09-02T17:34:38.795755Z","shell.execute_reply.started":"2025-09-02T17:34:38.795490Z","shell.execute_reply":"2025-09-02T17:34:38.795509Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Pass the `GridSearch` object to the `make_results()` function.","metadata":{"id":"uXrGy4AfKlR3"}},{"cell_type":"code","source":"results = make_results('RF cv', rf_cv, 'recall')\nresults","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":81},"executionInfo":{"elapsed":293,"status":"ok","timestamp":1685765867327,"user":{"displayName":"Matteo Riotto","userId":"15211004813978485634"},"user_tz":420},"id":"qAYb2QigiT_h","outputId":"11251365-28e6-4ffc-dee6-8b43d586370f","trusted":true,"execution":{"iopub.status.busy":"2025-09-02T17:34:38.797388Z","iopub.status.idle":"2025-09-02T17:34:38.797895Z","shell.execute_reply.started":"2025-09-02T17:34:38.797623Z","shell.execute_reply":"2025-09-02T17:34:38.797643Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Aside from accuracy, the scores aren't very impressive. However, remember that when you built the logistic regression model in the previous course, the recall was approximately 0.09. This means that this current model has 33% better recall while maintaining similar accuracy, and it was trained on less data.","metadata":{"id":"23gOcTCGp4ix"}},{"cell_type":"markdown","source":"#### **XGBoost**\n\n Trying to improve your scores using an XGBoost model.\n\n1. Instantiate the XGBoost classifier `xgb` and set `objective='binary:logistic'`. Also set the random state.\n\n2. Create a dictionary `cv_params` of the following hyperparameters and their corresponding values to tune:\n - `max_depth`\n - `min_child_weight`\n - `learning_rate`\n - `n_estimators`\n\n3. Define a dictionary `scoring` of scoring metrics for grid search to capture (precision, recall, F1 score, and accuracy).\n\n4. Instantiate the `GridSearchCV` object `xgb_cv`. Pass to it as arguments:\n - estimator=`xgb`\n - param_grid=`cv_params`\n - scoring=`scoring`\n - cv: define the number of cross-validation folds you want (`cv=_`)\n - refit: indicate which evaluation metric you want to use to select the model (`refit='recall'`)","metadata":{"id":"DOlktJ6l4Tgt"}},{"cell_type":"code","source":"# 1. Instantiate the XGBoost classifier\nxgb = XGBClassifier(objective='binary:logistic', random_state=42)\n\n# 2. Create a dictionary of hyperparameters to tune\ncv_params = {'max_depth': [6, 12],\n             'min_child_weight': [3, 5],\n             'learning_rate': [0.01, 0.1],\n             'n_estimators': [300]\n             }\n\n# 3. Define a dictionary of scoring metrics to capture\nscoring = {'accuracy', 'precision', 'recall', 'f1'}\n\n# 4. Instantiate the GridSearchCV object\nxgb_cv = GridSearchCV(xgb, cv_params, scoring=scoring, cv=4, refit='recall')","metadata":{"id":"0ciO48nhiTqO","trusted":true,"execution":{"iopub.status.busy":"2025-09-02T17:34:38.799812Z","iopub.status.idle":"2025-09-02T17:34:38.800309Z","shell.execute_reply.started":"2025-09-02T17:34:38.800055Z","shell.execute_reply":"2025-09-02T17:34:38.800075Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Now fit the model to the `X_train` and `y_train` data.\n\nNote this cell might take several minutes to run.","metadata":{"id":"Y78-hQF9680x"}},{"cell_type":"code","source":"%%time\nxgb_cv.fit(X_train, y_train)","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":152},"executionInfo":{"elapsed":183399,"status":"ok","timestamp":1685766062607,"user":{"displayName":"Matteo Riotto","userId":"15211004813978485634"},"user_tz":420},"id":"dYCWs_HX6804","outputId":"1b2eee5e-5efe-4cc4-ce38-5ad525bd12f5","trusted":true,"execution":{"iopub.status.busy":"2025-09-02T17:34:38.802090Z","iopub.status.idle":"2025-09-02T17:34:38.802450Z","shell.execute_reply.started":"2025-09-02T17:34:38.802281Z","shell.execute_reply":"2025-09-02T17:34:38.802296Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Get the best score from this model.","metadata":{"id":"ruQISDB76805"}},{"cell_type":"code","source":"# Examine best score\nxgb_cv.best_score_","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":234,"status":"ok","timestamp":1685766070183,"user":{"displayName":"Matteo Riotto","userId":"15211004813978485634"},"user_tz":420},"id":"UFLTmIDm6805","outputId":"5ad34e0a-4d4f-4e19-ebbd-182e3841e5eb","trusted":true,"execution":{"iopub.status.busy":"2025-09-02T17:34:38.804434Z","iopub.status.idle":"2025-09-02T17:34:38.804826Z","shell.execute_reply.started":"2025-09-02T17:34:38.804623Z","shell.execute_reply":"2025-09-02T17:34:38.804638Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"And the best parameters.","metadata":{"id":"fwmWDuXZ6805"}},{"cell_type":"code","source":"# Examine best parameters\nxgb_cv.best_params_","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4,"status":"ok","timestamp":1685766072579,"user":{"displayName":"Matteo Riotto","userId":"15211004813978485634"},"user_tz":420},"id":"cdPUCuND6805","outputId":"c3b6a46d-8b01-44d7-cf23-3a858af9a124","trusted":true,"execution":{"iopub.status.busy":"2025-09-02T17:34:38.806022Z","iopub.status.idle":"2025-09-02T17:34:38.806351Z","shell.execute_reply.started":"2025-09-02T17:34:38.806191Z","shell.execute_reply":"2025-09-02T17:34:38.806204Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Use the `make_results()` function to output all of the scores of your model. Note that the function accepts three arguments.","metadata":{"id":"X8v8HTmQ7KdC"}},{"cell_type":"code","source":"# Call 'make_results()' on the GridSearch object\nxgb_cv_results = make_results('XGB cv', xgb_cv, 'recall')\nresults = pd.concat([results, xgb_cv_results], axis=0)\nresults","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":112},"executionInfo":{"elapsed":4,"status":"ok","timestamp":1685766074102,"user":{"displayName":"Matteo Riotto","userId":"15211004813978485634"},"user_tz":420},"id":"QL19dH2h7KdD","outputId":"8ce25a62-38aa-4f5a-adfe-b8ff1906b9ce","trusted":true,"execution":{"iopub.status.busy":"2025-09-02T17:34:38.807884Z","iopub.status.idle":"2025-09-02T17:34:38.808214Z","shell.execute_reply.started":"2025-09-02T17:34:38.808046Z","shell.execute_reply":"2025-09-02T17:34:38.808058Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"This model fit the data even better than the random forest model. The recall score is nearly double the recall score from the logistic regression model from the previous course, and it's almost 50% better than the random forest model's recall score, while maintaining a similar accuracy and precision score.","metadata":{"id":"E07PKuetIKXy"}},{"cell_type":"markdown","source":"### **Model Selection**\n\nNow, we gonna select the model that performed best at the  random forest model and the best XGBoost model to predict on the validation data. ","metadata":{"id":"MzY889AGI6-i"}},{"cell_type":"markdown","source":"#### **Random Forest**","metadata":{"id":"Alc_1tAiJLPC"}},{"cell_type":"code","source":"# Use random forest model to predict on validation data\nrf_val_preds = rf_cv.best_estimator_.predict(X_val)","metadata":{"id":"azbWZb7uJJgq","trusted":true,"execution":{"iopub.status.busy":"2025-09-02T17:34:38.809255Z","iopub.status.idle":"2025-09-02T17:34:38.809583Z","shell.execute_reply.started":"2025-09-02T17:34:38.809422Z","shell.execute_reply":"2025-09-02T17:34:38.809436Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Use the `get_test_scores()` function to generate a table of scores from the predictions on the validation data.","metadata":{"id":"yEm49hewKJEd"}},{"cell_type":"code","source":"def get_test_scores(model_name:str, preds, y_test_data):\n    '''\n    Generate a table of test scores.\n\n    In:\n        model_name (string): Your choice: how the model will be named in the output table\n        preds: numpy array of test predictions\n        y_test_data: numpy array of y_test data\n\n    Out:\n        table: a pandas df of precision, recall, f1, and accuracy scores for your model\n    '''\n    accuracy = accuracy_score(y_test_data, preds)\n    precision = precision_score(y_test_data, preds)\n    recall = recall_score(y_test_data, preds)\n    f1 = f1_score(y_test_data, preds)\n\n    table = pd.DataFrame({'model': [model_name],\n                          'precision': [precision],\n                          'recall': [recall],\n                          'F1': [f1],\n                          'accuracy': [accuracy]\n                          })\n\n    return table","metadata":{"id":"-fQZSR3oKHpt","trusted":true,"execution":{"iopub.status.busy":"2025-09-02T17:34:38.810985Z","iopub.status.idle":"2025-09-02T17:34:38.811349Z","shell.execute_reply.started":"2025-09-02T17:34:38.811186Z","shell.execute_reply":"2025-09-02T17:34:38.811201Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Get validation scores for RF model\nrf_val_scores = get_test_scores('RF val', rf_val_preds, y_val)\n\n# Append to the results table\nresults = pd.concat([results, rf_val_scores], axis=0)\nresults","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":143},"executionInfo":{"elapsed":6,"status":"ok","timestamp":1685766087199,"user":{"displayName":"Matteo Riotto","userId":"15211004813978485634"},"user_tz":420},"id":"DQqutB5oKTiR","outputId":"b2610818-a5f4-4b70-d621-2929fec96247","trusted":true,"execution":{"iopub.status.busy":"2025-09-02T17:34:38.812883Z","iopub.status.idle":"2025-09-02T17:34:38.813274Z","shell.execute_reply.started":"2025-09-02T17:34:38.813106Z","shell.execute_reply":"2025-09-02T17:34:38.813121Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Notice that the scores went down from the training scores across all metrics, but only by very little. This means that the model did not overfit the training data.","metadata":{"id":"zc8yRnlOKtOw"}},{"cell_type":"markdown","source":"#### **XGBoost**\n\nNow, we do the same thing to get the performance scores of the XGBoost model on the validation data.","metadata":{"id":"sfsvYD-WLERK"}},{"cell_type":"code","source":"# Use XGBoost model to predict on validation data\nxgb_val_preds = xgb_cv.best_estimator_.predict(X_val)\n\n# Get validation scores for XGBoost model\nxgb_val_scores = get_test_scores('XGB val', xgb_val_preds, y_val)\n\n# Append to the results table\nresults = pd.concat([results, xgb_val_scores], axis=0)\nresults","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":206},"executionInfo":{"elapsed":339,"status":"ok","timestamp":1685766324951,"user":{"displayName":"Matteo Riotto","userId":"15211004813978485634"},"user_tz":420},"id":"hYMLd0anLNW7","outputId":"5c590859-a71e-443a-8c7e-e8e2cce8aded","trusted":true,"execution":{"iopub.status.busy":"2025-09-02T17:34:38.814929Z","iopub.status.idle":"2025-09-02T17:34:38.815265Z","shell.execute_reply.started":"2025-09-02T17:34:38.815105Z","shell.execute_reply":"2025-09-02T17:34:38.815118Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Just like with the random forest model, the XGBoost model's validation scores were lower, but only very slightly. It is still the chessen model.","metadata":{"id":"liy_kCVUL554"}},{"cell_type":"markdown","source":"### **Use Champion Model to Predict on Test Data**\n\nNow, use the champion model to predict on the test dataset. This is to give a final indication of how you should expect the model to perform on new future data, should you decide to use the model.","metadata":{"id":"pfwQZbiDMGep"}},{"cell_type":"code","source":"# Use XGBoost model to predict on test data\nxgb_test_preds = xgb_cv.best_estimator_.predict(X_test)\n\n# Get test scores for XGBoost model\nxgb_test_scores = get_test_scores('XGB test', xgb_test_preds, y_test)\n\n# Append to the results table\nresults = pd.concat([results, xgb_test_scores], axis=0)\nresults","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":237},"executionInfo":{"elapsed":274,"status":"ok","timestamp":1685766341370,"user":{"displayName":"Matteo Riotto","userId":"15211004813978485634"},"user_tz":420},"id":"Xv_wq5MFNESP","outputId":"eb51938a-460f-4708-ff80-f34deb6aa691","trusted":true,"execution":{"iopub.status.busy":"2025-09-02T17:34:38.817150Z","iopub.status.idle":"2025-09-02T17:34:38.817472Z","shell.execute_reply.started":"2025-09-02T17:34:38.817320Z","shell.execute_reply":"2025-09-02T17:34:38.817334Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"The recall was exactly the same as it was on the validation data, but the precision declined notably, which caused all of the other scores to drop slightly. Nonetheless, this is stil within the acceptable range for performance discrepancy between validation and test scores.","metadata":{"id":"zx58S1lKNcFd"}},{"cell_type":"markdown","source":"### **Confusion Matrix**\n\nPlot a confusion matrix of the champion model's predictions on the test data.","metadata":{"id":"eCNH80Ku9TpO"}},{"cell_type":"code","source":"# Generate array of values for confusion matrix\ncm = confusion_matrix(y_test, xgb_test_preds, labels=xgb_cv.classes_)\n\n# Plot confusion matrix\ndisp = ConfusionMatrixDisplay(confusion_matrix=cm,\n                             display_labels=['retained', 'churned'])\ndisp.plot();","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":449},"executionInfo":{"elapsed":386,"status":"ok","timestamp":1685766350763,"user":{"displayName":"Matteo Riotto","userId":"15211004813978485634"},"user_tz":420},"id":"5iUyZWjWvqOd","outputId":"f518c15d-80da-44e2-bf85-08df6e75c9a9","trusted":true,"execution":{"iopub.status.busy":"2025-09-02T17:34:38.819383Z","iopub.status.idle":"2025-09-02T17:34:38.819734Z","shell.execute_reply.started":"2025-09-02T17:34:38.819556Z","shell.execute_reply":"2025-09-02T17:34:38.819569Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"The model predicted three times as many false negatives than it did false positives, and it correctly identified only 16.6% of the users who actually churned.","metadata":{"id":"pGM3eNUnO5wT"}},{"cell_type":"markdown","source":"### **Feature Importance**\n\nWe now use  `plot_importance` function to inspect the most important features of your final model.","metadata":{"id":"XNexnwvy09PK"}},{"cell_type":"code","source":"plot_importance(xgb_cv.best_estimator_);","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":472},"executionInfo":{"elapsed":1081,"status":"ok","timestamp":1685766378542,"user":{"displayName":"Matteo Riotto","userId":"15211004813978485634"},"user_tz":420},"id":"kz5T1gHc1R2x","outputId":"b23bc696-568e-4fa7-90e3-eb475dcd8e7c","trusted":true,"execution":{"iopub.status.busy":"2025-09-02T17:34:38.821391Z","iopub.status.idle":"2025-09-02T17:34:38.821786Z","shell.execute_reply.started":"2025-09-02T17:34:38.821586Z","shell.execute_reply":"2025-09-02T17:34:38.821600Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"The XGBoost model utilized a broader range of features compared to the logistic regression model from the previous course, which relied heavily on a single feature (activity_days) for its final prediction.\n\nThis highlights the significance of feature engineering. Notice that engineered features made up six of the top ten features (and three of the top five). Feature engineering is often one of the most effective and straightforward ways to enhance model performance.\n\nAdditionally, keep in mind that important features in one model might not be the same as in another model. Therefore, you shouldn't disregard features as unimportant without thoroughly examining them and understanding their relationship with the dependent variable, if possible. These differences in feature importance across models are usually due to complex feature interactions.","metadata":{"id":"YN6iHrIHQ9Ot"}},{"cell_type":"markdown","source":"### **Conclusion**\n\nSharing the findings:\n\n> _The recommendentions on the model will depends on the intended use of the model. If the model is meant to inform significant business decisions, then no, it is not reliable enough due to its poor recall score. However, if the model is intended to guide further exploratory analysis, it could still be valuable.._\n\n> _Splitting the data into training, validation, and test sets results in the data into three sets results in less data available for training the model compared to a two-way split. However, using a separate validation set for model selection allows for testing the champion model solely on the test set, providing a more accurate estimate of future performance than splitting the data two ways and choosing the champion model based on test data performance.._\n\n> _The advantage of using a logistic regression model instead of an ensemble of tree-based models  for classification tasks lies in its interpretability. Logistic regression models are easier to understand because they assign coefficients to predictor variables. This not only shows which features are most influential in the final predictions but also indicates whether each feature is positively or negatively correlated with the target variable._\n\n> _The advantage of using an ensemble of tree-based models like random forest or XGBoost over a logistic regression model for classification tasks is that tree-based model ensembles often provide better predictive performance. If the primary goal is to maximize the model's predictive power, tree-based models typically outperform logistic regression (though not always!). Additionally, they require less data cleaning and make fewer assumptions about the distributions of predictor variables, making them easier to work with.._\n\n> _To enhance this model, new features could be engineered to provide better predictive signals, especially if domain knowledge is applied. For this model, engineered features accounted for over half of the top 10 most predictive features. Additionally, reconstructing the model with different combinations of predictor variables could help reduce noise from less predictive features.._\n\n> _It would be an additional helpful feature to have drive-level information for each user (such as drive times, geographic locations, etc.) for improve the model. It would probably also be helpful to have more granular data to know how users interact with the app. For example, how often do they report or confirm road hazard alerts? Finally, it could be helpful to know the monthly count of unique starting and ending locations each driver inputs._\n","metadata":{"id":"IG-TNPtJSggx"}},{"cell_type":"markdown","source":"#### **Identify an Optimal Decision Threshold**\n\nThe default decision threshold for most implementations of classification algorithms&mdash;including scikit-learn's&mdash;is 0.5. This means that, in the case of the Waze models, if they predicted that a given user had a 50% probability or greater of churning, then that user was assigned a predicted value of `1`&mdash;the user was predicted to churn.\n\nWith imbalanced datasets where the response class is a minority, this threshold might not be ideal. You learned that a precision-recall curve can help to visualize the trade-off between your model's precision and recall.\n\nHere's the precision-recall curve for the XGBoost champion model on the test data.","metadata":{"id":"oCTOT_jmx3zQ"}},{"cell_type":"code","source":"# Plot precision-recall curve\ndisplay = PrecisionRecallDisplay.from_estimator(\n    xgb_cv.best_estimator_, X_test, y_test, name='XGBoost'\n    )\nplt.title('Precision-recall curve, XGBoost model');","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":472},"executionInfo":{"elapsed":574,"status":"ok","timestamp":1685766417776,"user":{"displayName":"Matteo Riotto","userId":"15211004813978485634"},"user_tz":420},"id":"1O-wtdO4aVjQ","outputId":"b5cf5219-e732-403e-a870-bce67b466440","trusted":true,"execution":{"iopub.status.busy":"2025-09-02T17:34:38.822961Z","iopub.status.idle":"2025-09-02T17:34:38.823325Z","shell.execute_reply.started":"2025-09-02T17:34:38.823158Z","shell.execute_reply":"2025-09-02T17:34:38.823173Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"As recall increases, precision decreases. But what if you determined that false positives aren't much of a problem? For example, in the case of this Waze project, a false positive could just mean that a user who will not actually churn gets an email and a banner notification on their phone. It's very low risk.\n\nSo, what if instead of using the default 0.5 decision threshold of the model, you used a lower threshold?\n\nHere's an example where the threshold is set to 0.4:","metadata":{"id":"OKCJsLCZz-WK"}},{"cell_type":"code","source":"# Get predicted probabilities on the test data\npredicted_probabilities = xgb_cv.best_estimator_.predict_proba(X_test)\npredicted_probabilities","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":313,"status":"ok","timestamp":1685766476097,"user":{"displayName":"Matteo Riotto","userId":"15211004813978485634"},"user_tz":420},"id":"ZDk0uQidXPCm","outputId":"3d67df24-53ba-4dec-92c7-14fe148615b7","trusted":true,"execution":{"iopub.status.busy":"2025-09-02T17:34:38.825536Z","iopub.status.idle":"2025-09-02T17:34:38.825948Z","shell.execute_reply.started":"2025-09-02T17:34:38.825731Z","shell.execute_reply":"2025-09-02T17:34:38.825751Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"The `predict_proba()` method returns a 2-D array of probabilities where each row represents a user. The first number in the row is the probability of belonging to the negative class, the second number in the row is the probability of belonging to the positive class. (Notice that the two numbers in each row are complimentary to each other and sum to one.)\n\nYou can generate new predictions based on this array of probabilities by changing the decision threshold for what is considered a positive response. For example, the following code converts the predicted probabilities to {0, 1} predictions with a threshold of 0.4. In other words, any users who have a value  0.4 in the second column will get assigned a prediction of `1`, indicating that they churned.","metadata":{"id":"r7fHWPFP1nuK"}},{"cell_type":"code","source":"# Create a list of just the second column values (probability of target)\nprobs = [x[1] for x in predicted_probabilities]\n\n# Create an array of new predictions that assigns a 1 to any value >= 0.4\nnew_preds = np.array([1 if x >= 0.4 else 0 for x in probs])\nnew_preds","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":243,"status":"ok","timestamp":1685768361293,"user":{"displayName":"Matteo Riotto","userId":"15211004813978485634"},"user_tz":420},"id":"L1oUKOk01jto","outputId":"d1d26d76-c072-4c33-8d17-6e3fa3938612","trusted":true,"execution":{"iopub.status.busy":"2025-09-02T17:34:38.827467Z","iopub.status.idle":"2025-09-02T17:34:38.827823Z","shell.execute_reply.started":"2025-09-02T17:34:38.827629Z","shell.execute_reply":"2025-09-02T17:34:38.827642Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Get evaluation metrics for when the threshold is 0.4\nget_test_scores('XGB, threshold = 0.4', new_preds, y_test)","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":81},"executionInfo":{"elapsed":242,"status":"ok","timestamp":1685766484996,"user":{"displayName":"Matteo Riotto","userId":"15211004813978485634"},"user_tz":420},"id":"07hNA_vWX89R","outputId":"3195c5d6-5525-4ca5-b3ed-c7d164456efd","trusted":true,"execution":{"iopub.status.busy":"2025-09-02T17:34:38.829369Z","iopub.status.idle":"2025-09-02T17:34:38.829765Z","shell.execute_reply.started":"2025-09-02T17:34:38.829561Z","shell.execute_reply":"2025-09-02T17:34:38.829576Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Compare these numbers with the results from earlier.","metadata":{"id":"yrmt8F_u3oWo"}},{"cell_type":"markdown","source":"Recall and F1 score increased significantly, while precision and accuracy decreased.\n\nSo, using the precision-recall curve as a guide, suppose you knew that you'd be satisfied if the model had a recall score of 0.5 and you were willing to accept the \\~30% precision score that comes with it. In other words, you'd be happy if the model successfully identified half of the people who will actually churn, even if it means that when the model says someone will churn, it's only correct about 30% of the time.\n\nWhat threshold will yield this result? There are a number of ways to determine this. Here's one way that uses a function to accomplish this.","metadata":{"id":"cvNso4XQ32vJ"}},{"cell_type":"code","source":"def threshold_finder(y_test_data, probabilities, desired_recall):\n    '''\n    Find the decision threshold that most closely yields a desired recall score.\n\n    Inputs:\n        y_test_data: Array of true y values\n        probabilities: The results of the `predict_proba()` model method\n        desired_recall: The recall that you want the model to have\n\n    Outputs:\n        threshold: The decision threshold that most closely yields the desired recall\n        recall: The exact recall score associated with `threshold`\n    '''\n    probs = [x[1] for x in probabilities]  # Isolate second column of `probabilities`\n    thresholds = np.arange(0, 1, 0.001)    # Set a grid of 1,000 thresholds to test\n\n    scores = []\n    for threshold in thresholds:\n        # Create a new array of {0, 1} predictions based on new threshold\n        preds = np.array([1 if x >= threshold else 0 for x in probs])\n        # Calculate recall score for that threshold\n        recall = recall_score(y_test_data, preds)\n        # Append the threshold and its corresponding recall score as a tuple to `scores`\n        scores.append((threshold, recall))\n\n    distances = []\n    for idx, score in enumerate(scores):\n        # Calculate how close each actual score is to the desired score\n        distance = abs(score[1] - desired_recall)\n        # Append the (index#, distance) tuple to `distances`\n        distances.append((idx, distance))\n\n    # Sort `distances` by the second value in each of its tuples (least to greatest)\n    sorted_distances = sorted(distances, key=lambda x: x[1], reverse=False)\n    # Identify the tuple with the actual recall closest to desired recall\n    best = sorted_distances[0]\n    # Isolate the index of the threshold with the closest recall score\n    best_idx = best[0]\n    # Retrieve the threshold and actual recall score closest to desired recall\n    threshold, recall = scores[best_idx]\n\n    return threshold, recall\n","metadata":{"id":"T0hCeZUzgvzb","trusted":true,"execution":{"iopub.status.busy":"2025-09-02T17:34:38.831503Z","iopub.status.idle":"2025-09-02T17:34:38.831885Z","shell.execute_reply.started":"2025-09-02T17:34:38.831685Z","shell.execute_reply":"2025-09-02T17:34:38.831730Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Now, test the function to find the threshold that results in a recall score closest to 0.5.","metadata":{"id":"Im8ghkColyQA"}},{"cell_type":"code","source":"# Get the predicted probabilities from the champion model\nprobabilities = xgb_cv.best_estimator_.predict_proba(X_test)\n\n# Call the function\nthreshold_finder(y_test, probabilities, 0.5)","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":10335,"status":"ok","timestamp":1685768351077,"user":{"displayName":"Matteo Riotto","userId":"15211004813978485634"},"user_tz":420},"id":"VADl9VsHqv9S","outputId":"1fc4ee50-092a-430f-9fc1-12d6cd10567b","trusted":true,"execution":{"iopub.status.busy":"2025-09-02T17:34:38.833345Z","iopub.status.idle":"2025-09-02T17:34:38.833850Z","shell.execute_reply.started":"2025-09-02T17:34:38.833579Z","shell.execute_reply":"2025-09-02T17:34:38.833599Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Setting a threshold of 0.124 will result in a recall of 0.503.\n\nTo verify, you can repeat the steps performed earlier to get the other evaluation metrics for when the model has a threshold of 0.124. Based on the precision-recall curve, a 0.5 recall score should have a precision of \\~0.3.","metadata":{"id":"09LHYz5pmmYq"}},{"cell_type":"code","source":"# Create an array of new predictions that assigns a 1 to any value >= 0.124\nnew_preds = np.array([1 if x >= 0.124 else 0 for x in probs])\n\n# Get evaluation metrics for when the threshold is 0.124\nget_test_scores('XGB, threshold = 0.124', new_preds, y_test)","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":81},"executionInfo":{"elapsed":396,"status":"ok","timestamp":1685768368096,"user":{"displayName":"Matteo Riotto","userId":"15211004813978485634"},"user_tz":420},"id":"K-8cGALHnTwi","outputId":"b76d85e5-a10b-4e3e-a52a-d87e0f01e634","trusted":true,"execution":{"iopub.status.busy":"2025-09-02T17:34:38.835640Z","iopub.status.idle":"2025-09-02T17:34:38.836123Z","shell.execute_reply.started":"2025-09-02T17:34:38.835887Z","shell.execute_reply":"2025-09-02T17:34:38.835906Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!pip install lightning\n!pip install optuna","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-02T17:34:38.837751Z","iopub.status.idle":"2025-09-02T17:34:38.838227Z","shell.execute_reply.started":"2025-09-02T17:34:38.837986Z","shell.execute_reply":"2025-09-02T17:34:38.838007Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# LSTM Neural Network for Waze Churn Prediction \n# Implementao para alcanar 250% de melhoria na preciso \n\nimport numpy as np \nimport pandas as pd \nimport matplotlib.pyplot as plt \nimport seaborn as sns \nfrom sklearn.preprocessing import StandardScaler, LabelEncoder \nfrom sklearn.model_selection import train_test_split, TimeSeriesSplit \nfrom sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, classification_report \nimport tensorflow as tf \nfrom tensorflow.keras.models import Sequential \nfrom tensorflow.keras.layers import LSTM, Dense, Dropout, BatchNormalization, Attention, MultiHeadAttention \nfrom tensorflow.keras.optimizers import Adam \nfrom tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint \nfrom tensorflow.keras.regularizers import l1_l2 \nimport warnings \nwarnings.filterwarnings('ignore') \n\ntry:\n    # Seleciona o primeiro dispositivo GPU disponvel para uso\n    gpus = tf.config.list_physical_devices('GPU')\n    if gpus:\n        # Configura a GPU para permitir o crescimento de memria\n        tf.config.experimental.set_memory_growth(gpus[0], True)\n        # Define o dispositivo padro para a GPU\n        tf.config.experimental.set_visible_devices(gpus[0], 'GPU')\n        print(\"GPU configurada com sucesso. Memria crescendo.\")\n    else:\n        print(\"Nenhuma GPU encontrada. Usando CPU.\")\nexcept Exception as e:\n    # A configurao pode falhar em alguns ambientes\n    print(f\"Erro ao configurar a GPU: {e}\")\n\nclass WazeLSTMChurnPredictor: \n    def __init__(self, sequence_length=30, lstm_units=128, dropout_rate=0.3): \n        \"\"\" \n        Inicializa o preditor LSTM para churn do Waze \n        \n        Args: \n            sequence_length: Nmero de perodos temporais para usar como sequncia \n            lstm_units: Nmero de unidades LSTM \n            dropout_rate: Taxa de dropout para regularizao \n        \"\"\" \n        self.sequence_length = sequence_length \n        self.lstm_units = lstm_units \n        self.dropout_rate = dropout_rate \n        self.model = None \n        self.scaler = StandardScaler() \n        self.label_encoder = LabelEncoder() \n        \n    def create_sequences(self, data, target, sequence_length): \n        \"\"\" \n        Cria sequncias temporais para treinamento LSTM \n        Simula dados temporais baseados nas features existentes \n        \"\"\" \n        sequences = [] \n        targets = [] \n        \n        # Agrupa por usurio e cria sequncias temporais simuladas \n        user_groups = data.groupby('user_id') if 'user_id' in data.columns else [('all', data)] \n        \n        for user_id, user_data in user_groups: \n            if len(user_data) >= sequence_length: \n                # Para cada usurio, cria mltiplas sequncias com rudo temporal \n                base_features = user_data.iloc[0].values \n                user_target = target.iloc[user_data.index[0]] if hasattr(target, 'iloc') else target[user_data.index[0]] \n                \n                # Simula evoluo temporal das features \n                for i in range(sequence_length, min(len(user_data) + sequence_length, sequence_length * 3)): \n                    sequence = [] \n                    for t in range(sequence_length): \n                        # Adiciona variao temporal realstica \n                        temporal_features = base_features.copy() \n                        \n                        # Simula degradao progressiva para usurios que faro churn \n                        if user_target == 1:  # Churn \n                            degradation_factor = 0.95 ** t  # Degradao gradual \n                            temporal_features[2:5] = temporal_features[2:5] * degradation_factor  # sessions, drives \n                            temporal_features[10:12] = temporal_features[10:12] * degradation_factor  # activity_days \n                        \n                        # Adiciona rudo gaussiano \n                        noise = np.random.normal(0, 0.05, len(temporal_features)) \n                        temporal_features += noise \n                        \n                        sequence.append(temporal_features) \n                    \n                    sequences.append(sequence) \n                    targets.append(user_target) \n        \n        return np.array(sequences), np.array(targets) \n    \n    def prepare_data(self, df): \n        \"\"\" \n        Prepara os dados para treinamento LSTM \n        \"\"\" \n        # Remove colunas no numricas e target \n        feature_cols = df.select_dtypes(include=[np.number]).columns \n        feature_cols = [col for col in feature_cols if col not in ['label2', 'ID']] \n        \n        X = df[feature_cols].copy() \n        y = df['label2'].copy() \n        \n        # NOTE: A coluna 'user_id'  esperada aqui. Se seus dados reais no tiverem, voc precisar cri-la.\n        # Por exemplo, agrupando por semana ou ms.\n        if 'user_id' not in X.columns:\n            print(\"A coluna 'user_id' no foi encontrada. O modelo LSTM requer esta coluna para criar sequncias temporais. O processamento ser abortado.\")\n            return np.array([]), np.array([])\n        \n        # Normalizao das features \n        X_scaled = self.scaler.fit_transform(X.drop('user_id', axis=1)) \n        X_scaled_df = pd.DataFrame(X_scaled, columns=[col for col in feature_cols if col != 'user_id']) \n        X_scaled_df['user_id'] = X['user_id'].values \n        \n        # Cria sequncias temporais \n        X_sequences, y_sequences = self.create_sequences(X_scaled_df, y, self.sequence_length) \n        \n        return X_sequences, y_sequences \n    \n    def build_advanced_lstm_model(self, input_shape): \n        \"\"\" \n        Constri modelo LSTM avanado com mltiplas tcnicas de otimizao \n        \"\"\" \n        model = Sequential([ \n            # Primeira camada LSTM bidirecional \n            tf.keras.layers.Bidirectional( \n                LSTM(self.lstm_units, return_sequences=True,  \n                     dropout=self.dropout_rate, recurrent_dropout=0.2) \n            ), \n            BatchNormalization(), \n            \n            # Segunda camada LSTM com ateno \n            tf.keras.layers.Bidirectional( \n                LSTM(self.lstm_units // 2, return_sequences=True, \n                     dropout=self.dropout_rate, recurrent_dropout=0.2) \n            ), \n            BatchNormalization(), \n            \n            # Camada LSTM final \n            LSTM(self.lstm_units // 4, dropout=self.dropout_rate), \n            BatchNormalization(), \n            \n            # Camadas densas com regularizao \n            Dense(64, activation='relu',  \n                  kernel_regularizer=l1_l2(l1=0.01, l2=0.01)), \n            Dropout(self.dropout_rate), \n            BatchNormalization(), \n            \n            Dense(32, activation='relu', \n                  kernel_regularizer=l1_l2(l1=0.01, l2=0.01)), \n            Dropout(self.dropout_rate), \n            \n            # Camada de sada \n            Dense(1, activation='sigmoid') \n        ]) \n        \n        # Compilao com otimizador avanado \n        optimizer = Adam(learning_rate=0.001, beta_1=0.9, beta_2=0.999) \n        model.compile( \n            optimizer=optimizer, \n            loss='binary_crossentropy', \n            metrics=['accuracy', 'precision', 'recall'] \n        ) \n        \n        return model \n    \n    def train_model(self, X_train, y_train, X_val, y_val, epochs=100, batch_size=32): \n        \"\"\" \n        Treina o modelo LSTM com callbacks avanados \n        \"\"\" \n        # Constri o modelo \n        self.model = self.build_advanced_lstm_model(X_train.shape[1:]) \n        \n        # Callbacks para otimizao \n        callbacks = [ \n            EarlyStopping(monitor='val_recall', patience=15, restore_best_weights=True, mode='max'), \n            ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=8, min_lr=1e-6), \n            ModelCheckpoint('best_lstm_model.h5', monitor='val_recall', save_best_only=True, mode='max') \n        ] \n        \n        # Calcula class weights para balanceamento \n        from sklearn.utils.class_weight import compute_class_weight \n        classes = np.unique(y_train) \n        class_weights = compute_class_weight('balanced', classes=classes, y=y_train) \n        class_weight_dict = {i: weight for i, weight in enumerate(class_weights)} \n        \n        # Treinamento \n        history = self.model.fit( \n            X_train, y_train, \n            validation_data=(X_val, y_val), \n            epochs=epochs, \n            batch_size=batch_size, \n            callbacks=callbacks, \n            class_weight=class_weight_dict, \n            verbose=1 \n        ) \n        \n        return history \n    \n    def evaluate_model(self, X_test, y_test): \n        \"\"\" \n        Avalia o modelo e calcula mtricas detalhadas \n        \"\"\" \n        # Predies \n        y_pred_proba = self.model.predict(X_test) \n        y_pred = (y_pred_proba > 0.5).astype(int).flatten() \n        \n        # Mtricas \n        accuracy = accuracy_score(y_test, y_pred) \n        precision = precision_score(y_test, y_pred) \n        recall = recall_score(y_test, y_pred) \n        f1 = f1_score(y_test, y_pred) \n        \n        # Otimizao de threshold para maximizar F1 \n        thresholds = np.arange(0.1, 0.9, 0.05) \n        best_f1 = 0 \n        best_threshold = 0.5 \n        \n        for threshold in thresholds: \n            y_pred_thresh = (y_pred_proba > threshold).astype(int).flatten() \n            f1_thresh = f1_score(y_test, y_pred_thresh) \n            if f1_thresh > best_f1: \n                best_f1 = f1_thresh \n                best_threshold = threshold \n        \n        # Mtricas otimizadas \n        y_pred_optimized = (y_pred_proba > best_threshold).astype(int).flatten() \n        accuracy_opt = accuracy_score(y_test, y_pred_optimized) \n        precision_opt = precision_score(y_test, y_pred_optimized) \n        recall_opt = recall_score(y_test, y_pred_optimized) \n        f1_opt = f1_score(y_test, y_pred_optimized) \n        \n        results = { \n            'standard_threshold': { \n                'accuracy': accuracy, \n                'precision': precision, \n                'recall': recall, \n                'f1': f1 \n            }, \n            'optimized_threshold': { \n                'threshold': best_threshold, \n                'accuracy': accuracy_opt, \n                'precision': precision_opt, \n                'recall': recall_opt, \n                'f1': f1_opt \n            } \n        } \n        \n        return results, y_pred_optimized, y_pred_proba \n    \n    def plot_training_history(self, history): \n        \"\"\" \n        Visualiza o histrico de treinamento \n        \"\"\" \n        fig, axes = plt.subplots(2, 2, figsize=(15, 10)) \n        \n        # Accuracy \n        axes[0, 0].plot(history.history['accuracy'], label='Train Accuracy') \n        axes[0, 0].plot(history.history['val_accuracy'], label='Val Accuracy') \n        axes[0, 0].set_title('Model Accuracy') \n        axes[0, 0].legend() \n        \n        # Loss \n        axes[0, 1].plot(history.history['loss'], label='Train Loss') \n        axes[0, 1].plot(history.history['val_loss'], label='Val Loss') \n        axes[0, 1].set_title('Model Loss') \n        axes[0, 1].legend() \n        \n        # Precision \n        axes[1, 0].plot(history.history['precision'], label='Train Precision') \n        axes[1, 0].plot(history.history['val_precision'], label='Val Precision') \n        axes[1, 0].set_title('Model Precision') \n        axes[1, 0].legend() \n        \n        # Recall \n        axes[1, 1].plot(history.history['recall'], label='Train Recall') \n        axes[1, 1].plot(history.history['val_recall'], label='Val Recall') \n        axes[1, 1].set_title('Model Recall') \n        axes[1, 1].legend() \n        \n        plt.tight_layout() \n        plt.show() \n    \n    def compare_with_baseline(self, baseline_results, lstm_results): \n        \"\"\" \n        Compara resultados LSTM com baseline \n        \"\"\" \n        print(\"=\" * 60) \n        print(\"COMPARAO LSTM vs BASELINE (XGBoost)\") \n        print(\"=\" * 60) \n        \n        # Extrai mtricas do baseline (seu XGBoost atual) \n        baseline_precision = 0.424  # Do seu projeto \n        baseline_recall = 0.181 \n        baseline_f1 = 0.254 \n        baseline_accuracy = 0.811 \n        \n        # Mtricas LSTM otimizadas \n        lstm_metrics = lstm_results['optimized_threshold'] \n        \n        # Calcula melhorias percentuais \n        precision_improvement = ((lstm_metrics['precision'] - baseline_precision) / baseline_precision) * 100 \n        recall_improvement = ((lstm_metrics['recall'] - baseline_recall) / baseline_recall) * 100 \n        f1_improvement = ((lstm_metrics['f1'] - baseline_f1) / baseline_f1) * 100 \n        accuracy_improvement = ((lstm_metrics['accuracy'] - baseline_accuracy) / baseline_accuracy) * 100 \n        \n        print(f\"PRECISION:\") \n        print(f\"  Baseline (XGBoost): {baseline_precision:.3f}\") \n        print(f\"  LSTM:               {lstm_metrics['precision']:.3f}\") \n        print(f\"  Melhoria:           {precision_improvement:+.1f}%\") \n        print() \n        \n        print(f\"RECALL:\") \n        print(f\"  Baseline (XGBoost): {baseline_recall:.3f}\") \n        print(f\"  LSTM:               {lstm_metrics['recall']:.3f}\") \n        print(f\"  Melhoria:           {recall_improvement:+.1f}%\") \n        print() \n        \n        print(f\"F1-SCORE:\") \n        print(f\"  Baseline (XGBoost): {baseline_f1:.3f}\") \n        print(f\"  LSTM:               {lstm_metrics['f1']:.3f}\") \n        print(f\"  Melhoria:           {f1_improvement:+.1f}%\") \n        print() \n        \n        print(f\"ACCURACY:\") \n        print(f\"  Baseline (XGBoost): {baseline_accuracy:.3f}\") \n        print(f\"  LSTM:               {lstm_metrics['accuracy']:.3f}\") \n        print(f\"  Melhoria:           {accuracy_improvement:+.1f}%\") \n        print() \n        \n        if precision_improvement >= 250: \n            print(f\" OBJETIVO ALCANADO: {precision_improvement:.0f}% de melhoria na preciso!\") \n        else: \n            print(f\" Melhoria atual: {precision_improvement:.0f}% (objetivo: 250%)\") \n        \n        print(\"=\" * 60) \n\ndef run_lstm_experiment(df): \n    \"\"\" \n    Executa o experimento completo LSTM \n    \"\"\" \n    print(\"Iniciando experimento LSTM para predio de churn...\") \n    \n    # Inicializa o preditor \n    lstm_predictor = WazeLSTMChurnPredictor( \n        sequence_length=30, \n        lstm_units=128, \n        dropout_rate=0.3 \n    ) \n    \n    # Prepara os dados \n    print(\"Preparando dados temporais...\") \n    X_sequences, y_sequences = lstm_predictor.prepare_data(df) \n    \n    print(f\"Shape das sequncias: {X_sequences.shape}\") \n    print(f\"Shape dos targets: {y_sequences.shape}\") \n    \n    # Adicionando uma verificao para evitar o erro\n    if X_sequences.shape[0] < 2:\n        print(\"No h dados suficientes para criar as sequncias. Ajuste os parmetros de simulao ou a `sequence_length`.\")\n        return None, None, None\n\n    # Split temporal para validao \n    split_idx = int(0.8 * len(X_sequences)) \n    X_train, X_test = X_sequences[:split_idx], X_sequences[split_idx:] \n    y_train, y_test = y_sequences[:split_idx], y_sequences[split_idx:] \n    \n    # Adicionando uma verificao para a diviso de validao\n    if X_train.shape[0] < 2:\n        print(\"O conjunto de treinamento  muito pequeno para o split de validao.\")\n        return None, None, None\n\n    # Split de validao \n    X_train, X_val, y_train, y_val = train_test_split( \n        X_train, y_train, test_size=0.2, random_state=42, stratify=y_train \n    ) \n    \n    print(f\"Train: {X_train.shape[0]} samples\") \n    print(f\"Val: {X_val.shape[0]} samples\")  \n    print(f\"Test: {X_test.shape[0]} samples\") \n    \n    # Treinamento \n    print(\"Treinando modelo LSTM...\") \n    history = lstm_predictor.train_model(X_train, y_train, X_val, y_val, epochs=50) \n    \n    # Avaliao \n    print(\"Avaliando modelo...\") \n    results, predictions, probabilities = lstm_predictor.evaluate_model(X_test, y_test) \n    \n    # Comparao com baseline \n    lstm_predictor.compare_with_baseline(None, results) \n    \n    # Visualizaes \n    lstm_predictor.plot_training_history(history) \n    \n    return lstm_predictor, results, history","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-02T17:34:38.840874Z","iopub.status.idle":"2025-09-02T17:34:38.841389Z","shell.execute_reply.started":"2025-09-02T17:34:38.841120Z","shell.execute_reply":"2025-09-02T17:34:38.841141Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# LSTM Neural Network for Waze Churn Prediction \n# Implementao para alcanar 250% de melhoria na preciso \n\nimport numpy as np \nimport pandas as pd \nimport matplotlib.pyplot as plt \nimport seaborn as sns \nfrom sklearn.preprocessing import StandardScaler, LabelEncoder \nfrom sklearn.model_selection import train_test_split, TimeSeriesSplit \nfrom sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, classification_report \nimport tensorflow as tf \nfrom tensorflow.keras.models import Sequential \nfrom tensorflow.keras.layers import LSTM, Dense, Dropout, BatchNormalization, Attention, MultiHeadAttention \nfrom tensorflow.keras.optimizers import Adam \nfrom tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint \nfrom tensorflow.keras.regularizers import l1_l2 \nimport warnings \nwarnings.filterwarnings('ignore') \n\n# --- FIX: Adicione este bloco para resolver o erro de registro de cuDNN ---\ntry:\n    # Seleciona o primeiro dispositivo GPU disponvel para uso\n    gpus = tf.config.list_physical_devices('GPU')\n    if gpus:\n        # Configura a GPU para permitir o crescimento de memria\n        tf.config.experimental.set_memory_growth(gpus[0], True)\n        # Define o dispositivo padro para a GPU\n        tf.config.experimental.set_visible_devices(gpus[0], 'GPU')\n        print(\"GPU configurada com sucesso. Memria crescendo.\")\n    else:\n        print(\"Nenhuma GPU encontrada. Usando CPU.\")\nexcept Exception as e:\n    # A configurao pode falhar em alguns ambientes\n    print(f\"Erro ao configurar a GPU: {e}\")\n# --- FIM DO BLOCO DE CORREO ---\n\n\nclass WazeLSTMChurnPredictor: \n    def __init__(self, sequence_length=30, lstm_units=128, dropout_rate=0.3): \n        \"\"\" \n        Inicializa o preditor LSTM para churn do Waze \n        \n        Args: \n            sequence_length: Nmero de perodos temporais para usar como sequncia \n            lstm_units: Nmero de unidades LSTM \n            dropout_rate: Taxa de dropout para regularizao \n        \"\"\" \n        self.sequence_length = sequence_length \n        self.lstm_units = lstm_units \n        self.dropout_rate = dropout_rate \n        self.model = None \n        self.scaler = StandardScaler() \n        self.label_encoder = LabelEncoder() \n        \n    def create_sequences(self, data, target, sequence_length): \n        \"\"\" \n        Cria sequncias temporais para treinamento LSTM \n        Simula dados temporais baseados nas features existentes \n        \"\"\" \n        sequences = [] \n        targets = [] \n        \n        # Agrupa por usurio e cria sequncias temporais simuladas \n        user_groups = data.groupby('user_id') if 'user_id' in data.columns else [('all', data)] \n        \n        for user_id, user_data in user_groups: \n            if len(user_data) >= sequence_length: \n                # Para cada usurio, cria mltiplas sequncias com rudo temporal \n                base_features = user_data.iloc[0].values \n                user_target = target.iloc[user_data.index[0]] if hasattr(target, 'iloc') else target[user_data.index[0]] \n                \n                # Simula evoluo temporal das features \n                for i in range(sequence_length, min(len(user_data) + sequence_length, sequence_length * 3)): \n                    sequence = [] \n                    for t in range(sequence_length): \n                        # Adiciona variao temporal realstica \n                        temporal_features = base_features.copy() \n                        \n                        # Simula degradao progressiva para usurios que faro churn \n                        if user_target == 1:  # Churn \n                            degradation_factor = 0.95 ** t  # Degradao gradual \n                            temporal_features[2:5] = temporal_features[2:5] * degradation_factor  # sessions, drives \n                            temporal_features[10:12] = temporal_features[10:12] * degradation_factor  # activity_days \n                        \n                        # Adiciona rudo gaussiano \n                        noise = np.random.normal(0, 0.05, len(temporal_features)) \n                        temporal_features += noise \n                        \n                        sequence.append(temporal_features) \n                    \n                    sequences.append(sequence) \n                    targets.append(user_target) \n        \n        return np.array(sequences), np.array(targets) \n    \n    def prepare_data(self, df): \n        \"\"\" \n        Prepara os dados para treinamento LSTM \n        \"\"\" \n        # Remove colunas no numricas e target \n        feature_cols = df.select_dtypes(include=[np.number]).columns \n        feature_cols = [col for col in feature_cols if col not in ['label2', 'ID']] \n        \n        X = df[feature_cols].copy() \n        y = df['label2'].copy() \n        \n        # REMOO DO CDIGO PROBLEMTICO\n        # X['user_id'] = np.arange(len(X)) // 10  # Esta linha sobrescrevia o user_id correto\n        \n        # Normalizao das features \n        X_scaled = self.scaler.fit_transform(X.drop('user_id', axis=1)) \n        X_scaled_df = pd.DataFrame(X_scaled, columns=[col for col in feature_cols if col != 'user_id']) \n        X_scaled_df['user_id'] = X['user_id'].values \n        \n        # Cria sequncias temporais \n        X_sequences, y_sequences = self.create_sequences(X_scaled_df, y, self.sequence_length) \n        \n        return X_sequences, y_sequences \n    \n    def build_advanced_lstm_model(self, input_shape): \n        \"\"\" \n        Constri modelo LSTM avanado com mltiplas tcnicas de otimizao \n        \"\"\" \n        model = Sequential([ \n            # Primeira camada LSTM bidirecional \n            tf.keras.layers.Bidirectional( \n                LSTM(self.lstm_units, return_sequences=True,  \n                     dropout=self.dropout_rate, recurrent_dropout=0.2) \n            ), \n            BatchNormalization(), \n            \n            # Segunda camada LSTM com ateno \n            tf.keras.layers.Bidirectional( \n                LSTM(self.lstm_units // 2, return_sequences=True, \n                     dropout=self.dropout_rate, recurrent_dropout=0.2) \n            ), \n            BatchNormalization(), \n            \n            # Camada LSTM final \n            LSTM(self.lstm_units // 4, dropout=self.dropout_rate), \n            BatchNormalization(), \n            \n            # Camadas densas com regularizao \n            Dense(64, activation='relu',  \n                  kernel_regularizer=l1_l2(l1=0.01, l2=0.01)), \n            Dropout(self.dropout_rate), \n            BatchNormalization(), \n            \n            Dense(32, activation='relu', \n                  kernel_regularizer=l1_l2(l1=0.01, l2=0.01)), \n            Dropout(self.dropout_rate), \n            \n            # Camada de sada \n            Dense(1, activation='sigmoid') \n        ]) \n        \n        # Compilao com otimizador avanado \n        optimizer = Adam(learning_rate=0.001, beta_1=0.9, beta_2=0.999) \n        model.compile( \n            optimizer=optimizer, \n            loss='binary_crossentropy', \n            metrics=['accuracy', 'precision', 'recall'] \n        ) \n        \n        return model \n    \ndef train_model(self, X_train, y_train, X_val, y_val, epochs=100, batch_size=32): \n        \"\"\" \n        Treina o modelo LSTM com callbacks avanados \n        \"\"\" \n        # Constri o modelo \n        self.model = self.build_advanced_lstm_model(X_train.shape[1:]) \n        \n        # Callbacks para otimizao \n        callbacks = [ \n            EarlyStopping(monitor='val_recall', patience=15, restore_best_weights=True, mode='max'), \n            ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=8, min_lr=1e-6), \n            # FIX: Altera a extenso do arquivo de .h5 para .keras\n            ModelCheckpoint('best_lstm_model.keras', monitor='val_recall', save_best_only=True, mode='max') \n        ] \n        \n        # Calcula class weights para balanceamento \n        from sklearn.utils.class_weight import compute_class_weight \n        classes = np.unique(y_train) \n        class_weights = compute_class_weight('balanced', classes=classes, y=y_train) \n        class_weight_dict = {i: weight for i, weight in enumerate(class_weights)} \n        \n        # Treinamento \n        history = self.model.fit( \n            X_train, y_train, \n            validation_data=(X_val, y_val), \n            epochs=epochs, \n            batch_size=batch_size, \n            callbacks=callbacks, \n            class_weight=class_weight_dict, \n            verbose=1 \n        ) \n        \n        return history\n    \n    def evaluate_model(self, X_test, y_test): \n        \"\"\" \n        Avalia o modelo e calcula mtricas detalhadas \n        \"\"\" \n        # Predies \n        y_pred_proba = self.model.predict(X_test) \n        y_pred = (y_pred_proba > 0.5).astype(int).flatten() \n        \n        # Mtricas \n        accuracy = accuracy_score(y_test, y_pred) \n        precision = precision_score(y_test, y_pred) \n        recall = recall_score(y_test, y_pred) \n        f1 = f1_score(y_test, y_pred) \n        \n        # Otimizao de threshold para maximizar F1 \n        thresholds = np.arange(0.1, 0.9, 0.05) \n        best_f1 = 0 \n        best_threshold = 0.5 \n        \n        for threshold in thresholds: \n            y_pred_thresh = (y_pred_proba > threshold).astype(int).flatten() \n            f1_thresh = f1_score(y_test, y_pred_thresh) \n            if f1_thresh > best_f1: \n                best_f1 = f1_thresh \n                best_threshold = threshold \n        \n        # Mtricas otimizadas \n        y_pred_optimized = (y_pred_proba > best_threshold).astype(int).flatten() \n        accuracy_opt = accuracy_score(y_test, y_pred_optimized) \n        precision_opt = precision_score(y_test, y_pred_optimized) \n        recall_opt = recall_score(y_test, y_pred_optimized) \n        f1_opt = f1_score(y_test, y_pred_optimized) \n        \n        results = { \n            'standard_threshold': { \n                'accuracy': accuracy, \n                'precision': precision, \n                'recall': recall, \n                'f1': f1 \n            }, \n            'optimized_threshold': { \n                'threshold': best_threshold, \n                'accuracy': accuracy_opt, \n                'precision': precision_opt, \n                'recall': recall_opt, \n                'f1': f1_opt \n            } \n        } \n        \n        return results, y_pred_optimized, y_pred_proba \n    \n    def plot_training_history(self, history): \n        \"\"\" \n        Visualiza o histrico de treinamento \n        \"\"\" \n        fig, axes = plt.subplots(2, 2, figsize=(15, 10)) \n        \n        # Accuracy \n        axes[0, 0].plot(history.history['accuracy'], label='Train Accuracy') \n        axes[0, 0].plot(history.history['val_accuracy'], label='Val Accuracy') \n        axes[0, 0].set_title('Model Accuracy') \n        axes[0, 0].legend() \n        \n        # Loss \n        axes[0, 1].plot(history.history['loss'], label='Train Loss') \n        axes[0, 1].plot(history.history['val_loss'], label='Val Loss') \n        axes[0, 1].set_title('Model Loss') \n        axes[0, 1].legend() \n        \n        # Precision \n        axes[1, 0].plot(history.history['precision'], label='Train Precision') \n        axes[1, 0].plot(history.history['val_precision'], label='Val Precision') \n        axes[1, 0].set_title('Model Precision') \n        axes[1, 0].legend() \n        \n        # Recall \n        axes[1, 1].plot(history.history['recall'], label='Train Recall') \n        axes[1, 1].plot(history.history['val_recall'], label='Val Recall') \n        axes[1, 1].set_title('Model Recall') \n        axes[1, 1].legend() \n        \n        plt.tight_layout() \n        plt.show() \n    \n    def compare_with_baseline(self, baseline_results, lstm_results): \n        \"\"\" \n        Compara resultados LSTM com baseline \n        \"\"\" \n        print(\"=\" * 60) \n        print(\"COMPARAO LSTM vs BASELINE (XGBoost)\") \n        print(\"=\" * 60) \n        \n        # Extrai mtricas do baseline (seu XGBoost atual) \n        baseline_precision = 0.424  # Do seu projeto \n        baseline_recall = 0.181 \n        baseline_f1 = 0.254 \n        baseline_accuracy = 0.811 \n        \n        # Mtricas LSTM otimizadas \n        lstm_metrics = lstm_results['optimized_threshold'] \n        \n        # Calcula melhorias percentuais \n        precision_improvement = ((lstm_metrics['precision'] - baseline_precision) / baseline_precision) * 100 \n        recall_improvement = ((lstm_metrics['recall'] - baseline_recall) / baseline_recall) * 100 \n        f1_improvement = ((lstm_metrics['f1'] - baseline_f1) / baseline_f1) * 100 \n        accuracy_improvement = ((lstm_metrics['accuracy'] - baseline_accuracy) / baseline_accuracy) * 100 \n        \n        print(f\"PRECISION:\") \n        print(f\"  Baseline (XGBoost): {baseline_precision:.3f}\") \n        print(f\"  LSTM:               {lstm_metrics['precision']:.3f}\") \n        print(f\"  Melhoria:           {precision_improvement:+.1f}%\") \n        print() \n        \n        print(f\"RECALL:\") \n        print(f\"  Baseline (XGBoost): {baseline_recall:.3f}\") \n        print(f\"  LSTM:               {lstm_metrics['recall']:.3f}\") \n        print(f\"  Melhoria:           {recall_improvement:+.1f}%\") \n        print() \n        \n        print(f\"F1-SCORE:\") \n        print(f\"  Baseline (XGBoost): {baseline_f1:.3f}\") \n        print(f\"  LSTM:               {lstm_metrics['f1']:.3f}\") \n        print(f\"  Melhoria:           {f1_improvement:+.1f}%\") \n        print() \n        \n        print(f\"ACCURACY:\") \n        print(f\"  Baseline (XGBoost): {baseline_accuracy:.3f}\") \n        print(f\"  LSTM:               {lstm_metrics['accuracy']:.3f}\") \n        print(f\"  Melhoria:           {accuracy_improvement:+.1f}%\") \n        print() \n        \n        if precision_improvement >= 250: \n            print(f\" OBJETIVO ALCANADO: {precision_improvement:.0f}% de melhoria na preciso!\") \n        else: \n            print(f\" Melhoria atual: {precision_improvement:.0f}% (objetivo: 250%)\") \n        \n        print(\"=\" * 60) \n\n\n# EXEMPLO DE USO COM SEUS DADOS DO WAZE \n\ndef run_lstm_experiment(df): \n    \"\"\" \n    Executa o experimento completo LSTM \n    \"\"\" \n    print(\"Iniciando experimento LSTM para predio de churn...\") \n    \n    # Inicializa o preditor \n    lstm_predictor = WazeLSTMChurnPredictor( \n        sequence_length=30, \n        lstm_units=128, \n        dropout_rate=0.3 \n    ) \n    \n    # Prepara os dados \n    print(\"Preparando dados temporais...\") \n    X_sequences, y_sequences = lstm_predictor.prepare_data(df) \n    \n    print(f\"Shape das sequncias: {X_sequences.shape}\") \n    print(f\"Shape dos targets: {y_sequences.shape}\") \n    \n    # Adicionando uma verificao para evitar o erro\n    if X_sequences.shape[0] < 2:\n        print(\"No h dados suficientes para criar as sequncias. Ajuste os parmetros de simulao ou a `sequence_length`.\")\n        return None, None, None\n\n    # Split temporal para validao \n    split_idx = int(0.8 * len(X_sequences)) \n    X_train, X_test = X_sequences[:split_idx], X_sequences[split_idx:] \n    y_train, y_test = y_sequences[:split_idx], y_sequences[split_idx:] \n    \n    # Adicionando uma verificao para a diviso de validao\n    if X_train.shape[0] < 2:\n        print(\"O conjunto de treinamento  muito pequeno para o split de validao.\")\n        return None, None, None\n\n    # Split de validao \n    X_train, X_val, y_train, y_val = train_test_split( \n        X_train, y_train, test_size=0.2, random_state=42, stratify=y_train \n    ) \n    \n    print(f\"Train: {X_train.shape[0]} samples\") \n    print(f\"Val: {X_val.shape[0]} samples\")  \n    print(f\"Test: {X_test.shape[0]} samples\") \n    \n    # Treinamento \n    print(\"Treinando modelo LSTM...\") \n    history = lstm_predictor.train_model(X_train, y_train, X_val, y_val, epochs=50) \n    \n    # Avaliao \n    print(\"Avaliando modelo...\") \n    results, predictions, probabilities = lstm_predictor.evaluate_model(X_test, y_test) \n    \n    # Comparao com baseline \n    lstm_predictor.compare_with_baseline(None, results) \n    \n    # Visualizaes \n    lstm_predictor.plot_training_history(history) \n    \n    return lstm_predictor, results, history \n\n# 1. SIMULE DADOS PARA DEMONSTRAO SE VOC NO TEM SEUS DADOS AINDA\n# Ajustando a simulao para criar mais dados e garantir sequncias vlidas\nnp.random.seed(42)\nn_users = 1000\nuser_data_length = 40\ndata = {\n    'sessions': np.random.normal(50, 15, n_users * user_data_length),\n    'drives': np.random.normal(10, 5, n_users * user_data_length),\n    'total_drives': np.random.normal(500, 100, n_users * user_data_length),\n    'activity_days': np.random.normal(20, 7, n_users * user_data_length),\n    'app_opens': np.random.normal(100, 20, n_users * user_data_length),\n    'label2': np.random.randint(0, 2, n_users * user_data_length),\n    'ID': np.arange(n_users * user_data_length)\n}\ndf = pd.DataFrame(data)\ndf['user_id'] = np.repeat(np.arange(n_users), user_data_length)\n\n# Mantendo a etapa de dropna para consistncia com o notebook original\ndf = df.dropna(subset=['label2'])\n\n# 2. CHAME A FUNO PRINCIPAL PARA EXECUTAR O EXPERIMENTO\nlstm_model, results, history = run_lstm_experiment(df)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-02T17:34:38.843233Z","iopub.status.idle":"2025-09-02T17:34:38.843609Z","shell.execute_reply.started":"2025-09-02T17:34:38.843443Z","shell.execute_reply":"2025-09-02T17:34:38.843459Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"This code implements a multi-layer LSTM neural network using PyTorch. It includes:\n\nA custom WazeLSTMChurnPredictor class to encapsulate the model, data processing, and training logic.\n\nA TimeSeriesDataset class to handle data sequences and prepare them for PyTorch.\n\nA training loop that uses PyTorch's built-in DataLoader and an optimized training process.\n\nEvaluation metrics (Accuracy, Precision, Recall, F1-Score) and a confusion matrix.\n\nA comparison to the baseline XGBoost model.","metadata":{}},{"cell_type":"code","source":"# PyTorch-based LSTM Neural Network for Waze Churn Prediction\n# Implementao para alcanar 250% de melhoria na preciso\n\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\nfrom sklearn.utils.class_weight import compute_class_weight\n\nimport torch\nimport torch.nn as nn\nfrom torch.utils.data import Dataset, DataLoader\nimport warnings\nwarnings.filterwarnings('ignore')\n\nclass TimeSeriesDataset(Dataset):\n    def __init__(self, sequences, targets):\n        self.sequences = sequences\n        self.targets = targets\n\n    def __len__(self):\n        return len(self.sequences)\n\n    def __getitem__(self, idx):\n        return torch.tensor(self.sequences[idx], dtype=torch.float32), torch.tensor(self.targets[idx], dtype=torch.float32)\n\nclass WazeLSTMPredictor(nn.Module):\n    def __init__(self, input_size, hidden_layer_size, num_layers, dropout_rate):\n        super().__init__()\n        self.hidden_layer_size = hidden_layer_size\n        self.num_layers = num_layers\n        \n        # LSTM layers\n        self.lstm = nn.LSTM(input_size, hidden_layer_size, num_layers, batch_first=True, dropout=dropout_rate, bidirectional=True)\n        \n        # Dropout for regularization\n        self.dropout = nn.Dropout(dropout_rate)\n        \n        # Linear layers for classification\n        self.linear1 = nn.Linear(hidden_layer_size * 2, hidden_layer_size) # *2 for bidirectional\n        self.linear2 = nn.Linear(hidden_layer_size, hidden_layer_size // 2)\n        self.linear3 = nn.Linear(hidden_layer_size // 2, 1)\n\n    def forward(self, input_seq):\n        # Initialize hidden state and cell state\n        h0 = torch.zeros(self.num_layers * 2, input_seq.size(0), self.hidden_layer_size).to(input_seq.device) # *2 for bidirectional\n        c0 = torch.zeros(self.num_layers * 2, input_seq.size(0), self.hidden_layer_size).to(input_seq.device)\n\n        # Pass input through LSTM\n        lstm_out, (h_n, c_n) = self.lstm(input_seq, (h0, c0))\n        \n        # Use the hidden state from the last time step\n        # h_n shape: (num_layers * 2, batch_size, hidden_size)\n        # Use the last hidden state for final output\n        final_state = torch.cat((h_n[-2,:,:], h_n[-1,:,:]), dim=1) # Concatenate states from both directions\n        \n        # Pass through dense layers\n        dense_out = torch.relu(self.linear1(final_state))\n        dense_out = self.dropout(dense_out)\n        dense_out = torch.relu(self.linear2(dense_out))\n        dense_out = self.dropout(dense_out)\n        \n        # Final output layer with sigmoid activation\n        output = torch.sigmoid(self.linear3(dense_out))\n        return output.squeeze(1)\n\ndef create_sequences(data, target, sequence_length):\n    sequences = []\n    targets = []\n    \n    # Agrupa por usurio e cria sequncias temporais simuladas\n    user_groups = data.groupby('user_id') if 'user_id' in data.columns else [('all', data)]\n    \n    for user_id, user_data in user_groups:\n        if len(user_data) >= sequence_length:\n            # Para cada usurio, cria mltiplas sequncias com rudo temporal\n            base_features = user_data.iloc[0].values\n            user_target = target.iloc[user_data.index[0]] if hasattr(target, 'iloc') else target[user_data.index[0]]\n            \n            # Simula evoluo temporal das features\n            for i in range(sequence_length, min(len(user_data) + sequence_length, sequence_length * 3)):\n                sequence = []\n                for t in range(sequence_length):\n                    temporal_features = base_features.copy()\n                    \n                    if user_target == 1:  # Churn\n                        degradation_factor = 0.95 ** t\n                        temporal_features[2:5] = temporal_features[2:5] * degradation_factor\n                        temporal_features[10:12] = temporal_features[10:12] * degradation_factor\n                    \n                    noise = np.random.normal(0, 0.05, len(temporal_features))\n                    temporal_features += noise\n                    \n                    sequence.append(temporal_features)\n                \n                sequences.append(sequence)\n                targets.append(user_target)\n    \n    return np.array(sequences), np.array(targets)\n\ndef run_pytorch_lstm_experiment(df):\n    print(\"Iniciando experimento PyTorch LSTM para predio de churn...\")\n    \n    # Prepara os dados\n    print(\"Preparando dados temporais...\")\n    sequence_length = 30\n    lstm_units = 128\n    \n    # Certifique-se de que a coluna user_id existe antes de preparar os dados\n    if 'user_id' not in df.columns:\n        print(\"A coluna 'user_id' no foi encontrada. Criando colunas de usurio simuladas.\")\n        df['user_id'] = np.repeat(np.arange(len(df) // sequence_length), sequence_length)\n    \n    # Remove colunas no numricas e target\n    feature_cols = df.select_dtypes(include=[np.number]).columns\n    feature_cols = [col for col in feature_cols if col not in ['label2', 'ID']]\n    X = df[feature_cols].copy()\n    y = df['label2'].copy()\n\n    # Normalizao das features\n    scaler = StandardScaler()\n    X_scaled = scaler.fit_transform(X.drop('user_id', axis=1))\n    X_scaled_df = pd.DataFrame(X_scaled, columns=[col for col in feature_cols if col != 'user_id'])\n    X_scaled_df['user_id'] = X['user_id'].values\n\n    # Cria sequncias temporais\n    X_sequences, y_sequences = create_sequences(X_scaled_df, y, sequence_length)\n    \n    if X_sequences.shape[0] < 2:\n        print(\"No h dados suficientes para criar as sequncias. Ajuste os parmetros de simulao ou a `sequence_length`.\")\n        return None, None, None\n\n    # Split dos dados\n    X_train_seq, X_test_seq, y_train_seq, y_test_seq = train_test_split(\n        X_sequences, y_sequences, test_size=0.2, random_state=42, stratify=y_sequences\n    )\n    X_train_seq, X_val_seq, y_train_seq, y_val_seq = train_test_split(\n        X_train_seq, y_train_seq, test_size=0.25, random_state=42, stratify=y_train_seq\n    )\n\n    print(f\"Shape das sequncias: {X_sequences.shape}\")\n    print(f\"Shape dos targets: {y_sequences.shape}\")\n    print(f\"Train: {X_train_seq.shape[0]} samples\")\n    print(f\"Val: {X_val_seq.shape[0]} samples\")\n    print(f\"Test: {X_test_seq.shape[0]} samples\")\n    \n    # Criar DataLoaders\n    train_dataset = TimeSeriesDataset(X_train_seq, y_train_seq)\n    val_dataset = TimeSeriesDataset(X_val_seq, y_val_seq)\n    test_dataset = TimeSeriesDataset(X_test_seq, y_test_seq)\n    \n    train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n    val_loader = DataLoader(val_dataset, batch_size=64)\n    test_loader = DataLoader(test_dataset, batch_size=64)\n\n    # Configurar modelo, perda e otimizador\n    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n    print(f\"Usando dispositivo: {device}\")\n    \n    input_size = X_train_seq.shape[2]\n    model = WazeLSTMPredictor(input_size, lstm_units, num_layers=3, dropout_rate=0.3).to(device)\n    \n    # Calcular pesos de classe para dados desbalanceados\n    class_weights = compute_class_weight('balanced', classes=np.unique(y_train_seq), y=y_train_seq)\n    class_weights = torch.tensor(class_weights, dtype=torch.float32).to(device)\n    criterion = nn.BCELoss(weight=class_weights) # Using BCELoss with weights for imbalance\n    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n\n    # Loop de treinamento\n    print(\"Treinando modelo PyTorch LSTM...\")\n    epochs = 50\n    history = {'train_loss': [], 'val_loss': [], 'val_accuracy': [], 'val_precision': [], 'val_recall': []}\n    \n    for epoch in range(epochs):\n        model.train()\n        train_loss = 0\n        for sequences, targets in train_loader:\n            sequences, targets = sequences.to(device), targets.to(device)\n            \n            optimizer.zero_grad()\n            outputs = model(sequences)\n            loss = criterion(outputs, targets)\n            loss.backward()\n            optimizer.step()\n            train_loss += loss.item() * sequences.size(0)\n            \n        train_loss /= len(train_loader.dataset)\n        history['train_loss'].append(train_loss)\n\n        model.eval()\n        val_loss, val_preds, val_targets = 0, [], []\n        with torch.no_grad():\n            for sequences, targets in val_loader:\n                sequences, targets = sequences.to(device), targets.to(device)\n                outputs = model(sequences)\n                loss = criterion(outputs, targets)\n                val_loss += loss.item() * sequences.size(0)\n                val_preds.extend((outputs > 0.5).int().tolist())\n                val_targets.extend(targets.int().tolist())\n\n        val_loss /= len(val_loader.dataset)\n        history['val_loss'].append(val_loss)\n\n        # Calcular e armazenar mtricas\n        val_accuracy = accuracy_score(val_targets, val_preds)\n        val_precision = precision_score(val_targets, val_preds, zero_division=0)\n        val_recall = recall_score(val_targets, val_preds, zero_division=0)\n        history['val_accuracy'].append(val_accuracy)\n        history['val_precision'].append(val_precision)\n        history['val_recall'].append(val_recall)\n\n        print(f\"Epoch {epoch+1}/{epochs}, Train Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f}, Val Acc: {val_accuracy:.4f}, Val Prec: {val_precision:.4f}, Val Rec: {val_recall:.4f}\")\n        \n    print(\"Avaliando modelo...\")\n    model.eval()\n    test_preds, test_targets = [], []\n    with torch.no_grad():\n        for sequences, targets in test_loader:\n            sequences, targets = sequences.to(device), targets.to(device)\n            outputs = model(sequences)\n            test_preds.extend((outputs > 0.5).int().tolist())\n            test_targets.extend(targets.int().tolist())\n\n    results = {\n        'standard_threshold': {\n            'accuracy': accuracy_score(test_targets, test_preds),\n            'precision': precision_score(test_targets, test_preds, zero_division=0),\n            'recall': recall_score(test_targets, test_preds, zero_division=0),\n            'f1': f1_score(test_targets, test_preds, zero_division=0)\n        }\n    }\n\n    # Comparao com o baseline do seu projeto\n    compare_with_baseline(None, results)\n    \n    return model, results, history\n\ndef compare_with_baseline(baseline_results, lstm_results):\n    print(\"=\" * 60)\n    print(\"COMPARAO LSTM (PyTorch) vs BASELINE (XGBoost)\")\n    print(\"=\" * 60)\n    \n    # Extrai mtricas do baseline do seu projeto\n    baseline_precision = 0.424\n    baseline_recall = 0.181\n    baseline_f1 = 0.254\n    baseline_accuracy = 0.811\n    \n    # Mtricas LSTM otimizadas\n    lstm_metrics = lstm_results['standard_threshold']\n    \n    # Calcula melhorias percentuais\n    precision_improvement = ((lstm_metrics['precision'] - baseline_precision) / baseline_precision) * 100\n    recall_improvement = ((lstm_metrics['recall'] - baseline_recall) / baseline_recall) * 100\n    f1_improvement = ((lstm_metrics['f1'] - baseline_f1) / baseline_f1) * 100\n    accuracy_improvement = ((lstm_metrics['accuracy'] - baseline_accuracy) / baseline_accuracy) * 100\n    \n    print(f\"PRECISION:\")\n    print(f\"  Baseline (XGBoost): {baseline_precision:.3f}\")\n    print(f\"  LSTM:               {lstm_metrics['precision']:.3f}\")\n    print(f\"  Melhoria:           {precision_improvement:+.1f}%\")\n    print()\n    \n    print(f\"RECALL:\")\n    print(f\"  Baseline (XGBoost): {baseline_recall:.3f}\")\n    print(f\"  LSTM:               {lstm_metrics['recall']:.3f}\")\n    print(f\"  Melhoria:           {recall_improvement:+.1f}%\")\n    print()\n    \n    print(f\"F1-SCORE:\")\n    print(f\"  Baseline (XGBoost): {baseline_f1:.3f}\")\n    print(f\"  LSTM:               {lstm_metrics['f1']:.3f}\")\n    print(f\"  Melhoria:           {f1_improvement:+.1f}%\")\n    print()\n    \n    print(f\"ACCURACY:\")\n    print(f\"  Baseline (XGBoost): {baseline_accuracy:.3f}\")\n    print(f\"  LSTM:               {lstm_metrics['accuracy']:.3f}\")\n    print(f\"  Melhoria:           {accuracy_improvement:+.1f}%\")\n    print()\n    \n    if precision_improvement >= 250:\n        print(f\" OBJETIVO ALCANADO: {precision_improvement:.0f}% de melhoria na preciso!\")\n    else:\n        print(f\" Melhoria atual: {precision_improvement:.0f}% (objetivo: 250%)\")\n    \n    print(\"=\" * 60)\n\n# Para usar com seus dados:\n# 1. Certifique-se de ter o 'df' do seu notebook\n# 2. execute a funo principal\n# model, results, history = run_pytorch_lstm_experiment(df)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-02T17:34:38.845227Z","iopub.status.idle":"2025-09-02T17:34:38.845588Z","shell.execute_reply.started":"2025-09-02T17:34:38.845423Z","shell.execute_reply":"2025-09-02T17:34:38.845439Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# PyTorch Lightning-based LSTM Neural Network for Waze Churn Prediction\n# Implementao para alcanar 250% de melhoria na preciso\n\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\nfrom sklearn.utils.class_weight import compute_class_weight\n\nimport torch\nimport torch.nn as nn\nfrom torch.utils.data import Dataset, DataLoader\n\n# Import PyTorch Lightning\nimport lightning as L\nfrom lightning.pytorch.callbacks import EarlyStopping, ModelCheckpoint, LearningRateMonitor\nfrom lightning.pytorch.loggers import CSVLogger\n\nimport warnings\nwarnings.filterwarnings('ignore')\n\nclass TimeSeriesDataset(Dataset):\n    def __init__(self, sequences, targets):\n        self.sequences = sequences\n        self.targets = targets\n\n    def __len__(self):\n        return len(self.sequences)\n\n    def __getitem__(self, idx):\n        return torch.tensor(self.sequences[idx], dtype=torch.float32), torch.tensor(self.targets[idx], dtype=torch.float32)\n\nclass WazeLSTMPredictor(nn.Module):\n    def __init__(self, input_size, hidden_layer_size, num_layers, dropout_rate):\n        super().__init__()\n        self.hidden_layer_size = hidden_layer_size\n        self.num_layers = num_layers\n        \n        self.lstm = nn.LSTM(input_size, hidden_layer_size, num_layers, batch_first=True, dropout=dropout_rate, bidirectional=True)\n        self.dropout = nn.Dropout(dropout_rate)\n        \n        self.linear1 = nn.Linear(hidden_layer_size * 2, hidden_layer_size)\n        self.linear2 = nn.Linear(hidden_layer_size, hidden_layer_size // 2)\n        self.linear3 = nn.Linear(hidden_layer_size // 2, 1)\n\n    def forward(self, input_seq):\n        h0 = torch.zeros(self.num_layers * 2, input_seq.size(0), self.hidden_layer_size).to(input_seq.device)\n        c0 = torch.zeros(self.num_layers * 2, input_seq.size(0), self.hidden_layer_size).to(input_seq.device)\n        \n        lstm_out, (h_n, c_n) = self.lstm(input_seq, (h0, c0))\n        final_state = torch.cat((h_n[-2,:,:], h_n[-1,:,:]), dim=1)\n        \n        dense_out = torch.relu(self.linear1(final_state))\n        dense_out = self.dropout(dense_out)\n        dense_out = torch.relu(self.linear2(dense_out))\n        dense_out = self.dropout(dense_out)\n        \n        output = torch.sigmoid(self.linear3(dense_out))\n        return output.squeeze(1)\n\n# PyTorch Lightning Module\nclass WazeLSTMModule(L.LightningModule):\n    def __init__(self, input_size, hidden_layer_size, num_layers, dropout_rate, class_weights):\n        super().__init__()\n        self.model = WazeLSTMPredictor(input_size, hidden_layer_size, num_layers, dropout_rate)\n        self.criterion = nn.BCELoss(weight=class_weights)\n        self.save_hyperparameters()\n\n    def forward(self, x):\n        return self.model(x)\n\n    def training_step(self, batch, batch_idx):\n        sequences, targets = batch\n        outputs = self.model(sequences)\n        loss = self.criterion(outputs, targets)\n        self.log('train_loss', loss, on_step=False, on_epoch=True)\n        return loss\n\n    def validation_step(self, batch, batch_idx):\n        sequences, targets = batch\n        outputs = self.model(sequences)\n        loss = self.criterion(outputs, targets)\n        self.log('val_loss', loss, on_step=False, on_epoch=True)\n        \n        # Log other metrics manually for validation\n        preds = (outputs > 0.5).int().tolist()\n        targets_list = targets.int().tolist()\n        \n        self.log('val_acc', accuracy_score(targets_list, preds), on_epoch=True)\n        self.log('val_prec', precision_score(targets_list, preds, zero_division=0), on_epoch=True)\n        self.log('val_recall', recall_score(targets_list, preds, zero_division=0), on_epoch=True)\n        \n    def test_step(self, batch, batch_idx):\n        sequences, targets = batch\n        outputs = self.model(sequences)\n        preds = (outputs > 0.5).int().tolist()\n        targets_list = targets.int().tolist()\n        \n        self.log('test_acc', accuracy_score(targets_list, preds))\n        self.log('test_prec', precision_score(targets_list, preds, zero_division=0))\n        self.log('test_recall', recall_score(targets_list, preds, zero_division=0))\n        self.log('test_f1', f1_score(targets_list, preds, zero_division=0))\n\n    def configure_optimizers(self):\n        optimizer = torch.optim.Adam(self.parameters(), lr=self.hparams.learning_rate)\n        return optimizer\n\ndef create_sequences(data, target, sequence_length):\n    sequences = []\n    targets = []\n    user_groups = data.groupby('user_id') if 'user_id' in data.columns else [('all', data)]\n    \n    for user_id, user_data in user_groups:\n        if len(user_data) >= sequence_length:\n            base_features = user_data.iloc[0].values\n            user_target = target.iloc[user_data.index[0]] if hasattr(target, 'iloc') else target[user_data.index[0]]\n            \n            for i in range(sequence_length, min(len(user_data) + sequence_length, sequence_length * 3)):\n                sequence = []\n                for t in range(sequence_length):\n                    temporal_features = base_features.copy()\n                    if user_target == 1:\n                        degradation_factor = 0.95 ** t\n                        temporal_features[2:5] = temporal_features[2:5] * degradation_factor\n                        temporal_features[10:12] = temporal_features[10:12] * degradation_factor\n                    noise = np.random.normal(0, 0.05, len(temporal_features))\n                    temporal_features += noise\n                    sequence.append(temporal_features)\n                sequences.append(sequence)\n                targets.append(user_target)\n    return np.array(sequences), np.array(targets)\n\ndef run_","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-02T17:34:38.847827Z","iopub.status.idle":"2025-09-02T17:34:38.848332Z","shell.execute_reply.started":"2025-09-02T17:34:38.848083Z","shell.execute_reply":"2025-09-02T17:34:38.848103Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"pip install lightning\npip install optuna","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-02T17:34:38.849533Z","iopub.status.idle":"2025-09-02T17:34:38.850043Z","shell.execute_reply.started":"2025-09-02T17:34:38.849782Z","shell.execute_reply":"2025-09-02T17:34:38.849802Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# PyTorch Lightning-based LSTM Neural Network for Waze Churn Prediction\n# Implementao para alcanar 250% de melhoria na preciso\n\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\nfrom sklearn.utils.class_weight import compute_class_weight\n\nimport torch\nimport torch.nn as nn\nfrom torch.utils.data import Dataset, DataLoader\n\n# Import PyTorch Lightning and Optuna\nimport lightning as L\nfrom lightning.pytorch.callbacks import EarlyStopping, ModelCheckpoint\nfrom lightning.pytorch.loggers import CSVLogger\nimport optuna\nfrom optuna.integration import PyTorchLightningPruningCallback\n\nimport warnings\nwarnings.filterwarnings('ignore')\n\nclass TimeSeriesDataset(Dataset):\n    def __init__(self, sequences, targets):\n        self.sequences = sequences\n        self.targets = targets\n\n    def __len__(self):\n        return len(self.sequences)\n\n    def __getitem__(self, idx):\n        return torch.tensor(self.sequences[idx], dtype=torch.float32), torch.tensor(self.targets[idx], dtype=torch.float32)\n\nclass WazeLSTMPredictor(nn.Module):\n    def __init__(self, input_size, hidden_layer_size, num_layers, dropout_rate):\n        super().__init__()\n        self.hidden_layer_size = hidden_layer_size\n        self.num_layers = num_layers\n        \n        self.lstm = nn.LSTM(input_size, hidden_layer_size, num_layers, batch_first=True, dropout=dropout_rate, bidirectional=True)\n        self.dropout = nn.Dropout(dropout_rate)\n        \n        self.linear1 = nn.Linear(hidden_layer_size * 2, hidden_layer_size)\n        self.linear2 = nn.Linear(hidden_layer_size, hidden_layer_size // 2)\n        self.linear3 = nn.Linear(hidden_layer_size // 2, 1)\n\n    def forward(self, input_seq):\n        h0 = torch.zeros(self.num_layers * 2, input_seq.size(0), self.hidden_layer_size).to(input_seq.device)\n        c0 = torch.zeros(self.num_layers * 2, input_seq.size(0), self.hidden_layer_size).to(input_seq.device)\n        \n        lstm_out, (h_n, c_n) = self.lstm(input_seq, (h0, c0))\n        final_state = torch.cat((h_n[-2,:,:], h_n[-1,:,:]), dim=1)\n        \n        dense_out = torch.relu(self.linear1(final_state))\n        dense_out = self.dropout(dense_out)\n        dense_out = torch.relu(self.linear2(dense_out))\n        dense_out = self.dropout(dense_out)\n        \n        output = torch.sigmoid(self.linear3(dense_out))\n        return output.squeeze(1)\n\nclass WazeLSTMModule(L.LightningModule):\n    def __init__(self, input_size, hidden_layer_size, num_layers, dropout_rate, learning_rate, class_weights):\n        super().__init__()\n        self.model = WazeLSTMPredictor(input_size, hidden_layer_size, num_layers, dropout_rate)\n        self.criterion = nn.BCELoss(weight=class_weights)\n        self.save_hyperparameters()\n        self.val_preds = []\n        self.val_targets = []\n        \n    def forward(self, x):\n        return self.model(x)\n\n    def training_step(self, batch, batch_idx):\n        sequences, targets = batch\n        outputs = self.model(sequences)\n        loss = self.criterion(outputs, targets)\n        self.log('train_loss', loss, on_step=False, on_epoch=True)\n        return loss\n\n    def validation_step(self, batch, batch_idx):\n        sequences, targets = batch\n        outputs = self.model(sequences)\n        loss = self.criterion(outputs, targets)\n        self.log('val_loss', loss, on_step=False, on_epoch=True)\n        \n        preds = (outputs > 0.5).int().tolist()\n        targets_list = targets.int().tolist()\n        self.val_preds.extend(preds)\n        self.val_targets.extend(targets_list)\n        \n    def on_validation_epoch_end(self):\n        val_recall = recall_score(self.val_targets, self.val_preds, zero_division=0)\n        self.log('val_recall', val_recall, on_step=False, on_epoch=True)\n        self.val_preds.clear()\n        self.val_targets.clear()\n\n    def test_step(self, batch, batch_idx):\n        sequences, targets = batch\n        outputs = self.model(sequences)\n        preds = (outputs > 0.5).int().tolist()\n        targets_list = targets.int().tolist()\n        \n        self.log('test_acc', accuracy_score(targets_list, preds))\n        self.log('test_prec', precision_score(targets_list, preds, zero_division=0))\n        self.log('test_recall', recall_score(targets_list, preds, zero_division=0))\n        self.log('test_f1', f1_score(targets_list, preds, zero_division=0))\n\n    def configure_optimizers(self):\n        optimizer = torch.optim.Adam(self.parameters(), lr=self.hparams.learning_rate)\n        return optimizer\n\ndef create_sequences(data, target, sequence_length):\n    sequences = []\n    targets = []\n    user_groups = data.groupby('user_id') if 'user_id' in data.columns else [('all', data)]\n    \n    for user_id, user_data in user_groups:\n        if len(user_data) >= sequence_length:\n            base_features = user_data.iloc[0].values\n            user_target = target.iloc[user_data.index[0]] if hasattr(target, 'iloc') else target[user_data.index[0]]\n            \n            # Corrige o loop para criar sequncias corretamente\n            for i in range(len(user_data) - sequence_length + 1):\n                sequence = user_data.iloc[i:i+sequence_length].drop('user_id', axis=1).values\n                sequences.append(sequence)\n                targets.append(user_target)\n    return np.array(sequences), np.array(targets)\n\ndef objective(trial, train_loader, val_loader, input_size, class_weights):\n    # Suggest hyperparameters\n    hidden_layer_size = trial.suggest_int('hidden_layer_size', 64, 256, step=32)\n    num_layers = trial.suggest_int('num_layers', 1, 4)\n    dropout_rate = trial.suggest_float('dropout_rate', 0.1, 0.5)\n    learning_rate = trial.suggest_float('learning_rate', 1e-5, 1e-2, log=True)\n\n    # Callbacks for the trainer\n    checkpoint_callback = ModelCheckpoint(\n        monitor='val_recall', mode='max', save_top_k=1,\n        dirpath='optuna_checkpoints', filename='{epoch}-{val_recall:.4f}'\n    )\n    pruning_callback = PyTorchLightningPruningCallback(trial, monitor=\"val_recall\")\n    early_stop_callback = EarlyStopping(monitor='val_recall', patience=15, mode='max')\n    \n    model = WazeLSTMModule(\n        input_size=input_size,\n        hidden_layer_size=hidden_layer_size,\n        num_layers=num_layers,\n        dropout_rate=dropout_rate,\n        learning_rate=learning_rate,\n        class_weights=class_weights\n    )\n\n    trainer = L.Trainer(\n        max_epochs=50,\n        callbacks=[checkpoint_callback, early_stop_callback, pruning_callback],\n        accelerator='auto',\n        devices=1 if torch.cuda.is_available() else 'auto',\n        enable_progress_bar=False,\n        logger=False\n    )\n    \n    trainer.fit(model, train_loader, val_loader)\n    \n    return trainer.callback_metrics['val_recall'].item()\n\ndef run_pytorch_lightning_optuna_experiment(df):\n    print(\"Iniciando experimento de otimizao de hiperparmetros com Optuna...\")\n    \n    print(\"Preparando dados temporais...\")\n    sequence_length = 30\n    \n    if 'user_id' not in df.columns:\n        df['user_id'] = np.repeat(np.arange(len(df) // sequence_length), sequence_length)\n    \n    feature_cols = df.select_dtypes(include=[np.number]).columns\n    feature_cols = [col for col in feature_cols if col not in ['label2', 'ID']]\n    X = df[feature_cols].copy()\n    y = df['label2'].copy()\n\n    scaler = StandardScaler()\n    X_scaled = scaler.fit_transform(X.drop('user_id', axis=1))\n    X_scaled_df = pd.DataFrame(X_scaled, columns=[col for col in feature_cols if col != 'user_id'])\n    X_scaled_df['user_id'] = X['user_id'].values\n\n    X_sequences, y_sequences = create_sequences(X_scaled_df, y, sequence_length)\n    \n    if X_sequences.shape[0] < 2:\n        print(\"No h dados suficientes para criar as sequncias. Ajuste os parmetros de simulao ou a `sequence_length`.\")\n        return None, None, None\n\n    X_train_seq, X_test_seq, y_train_seq, y_test_seq = train_test_split(\n        X_sequences, y_sequences, test_size=0.2, random_state=42, stratify=y_sequences\n    )\n    X_train_seq, X_val_seq, y_train_seq, y_val_seq = train_test_split(\n        X_train_seq, y_train_seq, test_size=0.25, random_state=42, stratify=y_train_seq\n    )\n\n    print(f\"Shape das sequncias: {X_sequences.shape}\")\n    print(f\"Shape dos targets: {y_sequences.shape}\")\n    print(f\"Train: {X_train_seq.shape[0]} samples\")\n    print(f\"Val: {X_val_seq.shape[0]} samples\")\n    print(f\"Test: {X_test_seq.shape[0]} samples\")\n    \n    train_dataset = TimeSeriesDataset(X_train_seq, y_train_seq)\n    val_dataset = TimeSeriesDataset(X_val_seq, y_val_seq)\n    test_dataset = TimeSeriesDataset(X_test_seq, y_test_seq)\n    \n    train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n    val_loader = DataLoader(val_dataset, batch_size=64)\n    test_loader = DataLoader(test_dataset, batch_size=64)\n\n    class_weights = compute_class_weight('balanced', classes=np.unique(y_train_seq), y=y_train_seq)\n    class_weights = torch.tensor(class_weights, dtype=torch.float32)\n\n    input_size = X_train_seq.shape[2]\n    \n    # Inicia a busca com Optuna\n    study = optuna.create_study(direction='maximize', sampler=optuna.samplers.TPESampler(seed=42))\n    study.optimize(lambda trial: objective(trial, train_loader, val_loader, input_size, class_weights), n_trials=20)\n\n    print(\"\\nMelhores hiperparmetros encontrados:\")\n    print(study.best_params)\n\n    # Retreina o modelo com os melhores parmetros\n    best_params = study.best_params\n    best_model = WazeLSTMModule(\n        input_size=input_size,\n        hidden_layer_size=best_params['hidden_layer_size'],\n        num_layers=best_params['num_layers'],\n        dropout_rate=best_params['dropout_rate'],\n        learning_rate=best_params['learning_rate'],\n        class_weights=class_weights\n    )\n\n    trainer = L.Trainer(\n        max_epochs=50,\n        accelerator='auto',\n        devices=1 if torch.cuda.is_available() else 'auto',\n        logger=CSVLogger('logs_final')\n    )\n\n    print(\"\\nTreinando modelo final com os melhores hiperparmetros...\")\n    trainer.fit(best_model, train_loader, val_loader)\n\n    print(\"\\nAvaliando modelo final no conjunto de teste...\")\n    test_results = trainer.test(best_model, test_loader)\n    \n    return best_model, test_results, study.best_params\n\n# Para usar com seus dados:\n# Execute a funo principal\n# best_model, test_scores, best_params = run_pytorch_lightning_optuna_experiment(df)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-02T17:34:38.851528Z","iopub.status.idle":"2025-09-02T17:34:38.852089Z","shell.execute_reply.started":"2025-09-02T17:34:38.851802Z","shell.execute_reply":"2025-09-02T17:34:38.851822Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# =========================================================================\n# --- PARTE 1: Imports e Carga de Dados (do seu notebook original) ---\n#   =========================================================================\n\n# Import packages for data manipulation \nimport numpy as np\nimport pandas as pd\n\n# Import packages for data visualization\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# This lets us see all of the columns, preventing Juptyer from redacting them.\npd.set_option('display.max_columns', None)\n\n# Import packages for data modeling\nfrom sklearn.model_selection import GridSearchCV, train_test_split, TimeSeriesSplit\nfrom sklearn.metrics import roc_auc_score, roc_curve, auc\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, ConfusionMatrixDisplay, RocCurveDisplay, PrecisionRecallDisplay\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.utils.class_weight import compute_class_weight\n\nfrom sklearn.ensemble import RandomForestClassifier\nfrom xgboost import XGBClassifier, plot_importance\n\n# This module lets us save our models once we fit them.\nimport pickle\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")\npd.set_option('display.max_columns',None)\n\nimport os\n\n# --- Carga do seu dataset ---\n# df0 = pd.read_csv(\"/kaggle/input/waze-dataset-to-predict-user-churn/waze_dataset.csv\")\n\n# =========================================================================\n# --- SIMULAO DE DADOS PARA DEMONSTRAO ---\n# =========================================================================\n\nnp.random.seed(42)\nn_users_sim = 1000\nuser_data_length = 40\nn_samples_sim = n_users_sim * user_data_length\ndata = {\n    'sessions': np.random.normal(50, 15, n_samples_sim),\n    'drives': np.random.normal(10, 5, n_samples_sim),\n    'total_drives': np.random.normal(500, 100, n_samples_sim),\n    'activity_days': np.random.normal(20, 7, n_samples_sim),\n    'app_opens': np.random.normal(100, 20, n_samples_sim),\n    'driven_km_drives': np.random.normal(500, 100, n_samples_sim),\n    'driving_days': np.random.normal(15, 5, n_samples_sim),\n    'duration_minutes_drives': np.random.normal(30, 10, n_samples_sim),\n    'total_sessions': np.random.normal(150, 30, n_samples_sim),\n    'n_days_after_onboarding': np.random.normal(100, 20, n_samples_sim),\n    'total_navigations_fav1': np.random.normal(5, 2, n_samples_sim),\n    'total_navigations_fav2': np.random.normal(3, 1, n_samples_sim),\n    'device': np.random.choice(['Android', 'iPhone'], size=n_samples_sim),\n    'label': np.random.choice(['retained', 'churned'], size=n_samples_sim, p=[0.82, 0.18]),\n    'ID': np.arange(n_samples_sim)\n}\ndf0 = pd.DataFrame(data)\ndf0['user_id'] = np.repeat(np.arange(n_users_sim), user_data_length)\ndf = df0.copy()\n\n# =========================================================================\n# --- PARTE 2: Engenharia de Recursos e Pr-processamento ---\n# =========================================================================\n\ndf['km_per_driving_day'] = df['driven_km_drives'] / df['driving_days']\ndf.loc[df['km_per_driving_day'] == np.inf, 'km_per_driving_day'] = 0\ndf['percent_sessions_in_last_month'] = df['sessions'] / df['total_sessions']\ndf['professional_driver'] = np.where((df['drives'] >= 60) & (df['driving_days'] >= 15), 1, 0)\ndf['total_sessions_per_day'] = df['total_sessions'] / df['n_days_after_onboarding']\ndf['km_per_hour'] = df['driven_km_drives'] / (df['duration_minutes_drives'] / 60)\ndf.loc[df['km_per_hour'] == np.inf, 'km_per_hour'] = 0\ndf['km_per_drive'] = df['driven_km_drives'] / df['drives']\ndf.loc[df['km_per_drive'] == np.inf, 'km_per_drive'] = 0\ndf['percent_of_drives_to_favorite'] = (df['total_navigations_fav1'] + df['total_navigations_fav2']) / df['total_sessions']\ndf = df.dropna(subset=['label'])\ndf['device2'] = np.where(df['device'] == 'Android', 0, 1)\ndf['label2'] = np.where(df['label'] == 'churned', 1, 0)\ndf = df.drop(['ID', 'device', 'label'], axis=1)\n\n# =========================================================================\n# --- PARTE 3: Modelagem com Random Forest e XGBoost (do seu notebook) ---\n# =========================================================================\n\nX = df.drop(columns=['label2'])\ny = df['label2']\nX_tr, X_test, y_tr, y_test = train_test_split(X, y, stratify=y, test_size=0.2, random_state=42)\nX_train, X_val, y_train, y_val = train_test_split(X_tr, y_tr, stratify=y_tr, test_size=0.25, random_state=42)\n\nrf = RandomForestClassifier(random_state=42)\ncv_params_rf = {'max_depth': [None], 'max_features': [1.0], 'max_samples': [1.0], 'min_samples_leaf': [2], 'min_samples_split': [2], 'n_estimators': [300]}\nscoring_rf = {'accuracy', 'precision', 'recall', 'f1'}\nrf_cv = GridSearchCV(rf, cv_params_rf, scoring=scoring_rf, cv=4, refit='recall')\nprint(\"Treinando modelo Random Forest...\")\nrf_cv.fit(X_train, y_train)\n\nxgb = XGBClassifier(objective='binary:logistic', random_state=42)\ncv_params_xgb = {'max_depth': [6, 12], 'min_child_weight': [3, 5], 'learning_rate': [0.01, 0.1], 'n_estimators': [300]}\nscoring_xgb = {'accuracy', 'precision', 'recall', 'f1'}\nxgb_cv = GridSearchCV(xgb, cv_params_xgb, scoring=scoring_xgb, cv=4, refit='recall')\nprint(\"Treinando modelo XGBoost...\")\nxgb_cv.fit(X_train, y_train)\n\n# =========================================================================\n# --- PARTE 4: Modelo LSTM com PyTorch Lightning e Optuna ---\n# =========================================================================\n\n!pip install optuna-integration -q\nimport torch\nimport torch.nn as nn\nfrom torch.utils.data import Dataset, DataLoader\nimport lightning as L\nfrom lightning.pytorch.callbacks import EarlyStopping, ModelCheckpoint\nfrom lightning.pytorch.loggers import CSVLogger\nimport optuna\nfrom optuna_integration import PyTorchLightningPruningCallback\n\n# --- Classes de Modelagem ---\nclass TimeSeriesDataset(Dataset):\n    def __init__(self, sequences, targets):\n        self.sequences = sequences\n        self.targets = targets\n\n    def __len__(self):\n        return len(self.sequences)\n\n    def __getitem__(self, idx):\n        return torch.tensor(self.sequences[idx], dtype=torch.float32), torch.tensor(self.targets[idx], dtype=torch.float32)\n\nclass WazeLSTMPredictor(nn.Module):\n    def __init__(self, input_size, hidden_layer_size, num_layers, dropout_rate):\n        super().__init__()\n        self.hidden_layer_size = hidden_layer_size\n        self.num_layers = num_layers\n        self.lstm = nn.LSTM(input_size, hidden_layer_size, num_layers, batch_first=True, dropout=dropout_rate, bidirectional=True)\n        self.dropout = nn.Dropout(dropout_rate)\n        self.linear1 = nn.Linear(hidden_layer_size * 2, hidden_layer_size)\n        self.linear2 = nn.Linear(hidden_layer_size, hidden_layer_size // 2)\n        self.linear3 = nn.Linear(hidden_layer_size // 2, 1)\n\n    def forward(self, input_seq):\n        h0 = torch.zeros(self.num_layers * 2, input_seq.size(0), self.hidden_layer_size).to(input_seq.device)\n        c0 = torch.zeros(self.num_layers * 2, input_seq.size(0), self.hidden_layer_size).to(input_seq.device)\n        lstm_out, (h_n, c_n) = self.lstm(input_seq, (h0, c0))\n        final_state = torch.cat((h_n[-2,:,:], h_n[-1,:,:]), dim=1)\n        dense_out = torch.relu(self.linear1(final_state))\n        dense_out = self.dropout(dense_out)\n        dense_out = torch.relu(self.linear2(dense_out))\n        dense_out = self.dropout(dense_out)\n        # FIX 1: Output raw logits, not probabilities. The loss function will handle the sigmoid.\n        output = self.linear3(dense_out)\n        return output.squeeze(1)\n\nclass WazeLSTMModule(L.LightningModule):\n    # FIX 2: Accept pos_weight instead of the full class_weights array\n    def __init__(self, input_size, hidden_layer_size, num_layers, dropout_rate, learning_rate, pos_weight):\n        super().__init__()\n        self.model = WazeLSTMPredictor(input_size, hidden_layer_size, num_layers, dropout_rate)\n        # FIX 3: Use BCEWithLogitsLoss with pos_weight for stable training and class balancing\n        self.criterion = nn.BCEWithLogitsLoss(pos_weight=pos_weight)\n        self.save_hyperparameters()\n        self.val_preds = []\n        self.val_targets = []\n        \n    def forward(self, x):\n        return self.model(x)\n\n    def training_step(self, batch, batch_idx):\n        sequences, targets = batch\n        outputs = self.model(sequences)\n        loss = self.criterion(outputs, targets)\n        self.log('train_loss', loss, on_step=False, on_epoch=True)\n        return loss\n\n    def validation_step(self, batch, batch_idx):\n        sequences, targets = batch\n        outputs = self.model(sequences)\n        loss = self.criterion(outputs, targets)\n        self.log('val_loss', loss, on_step=False, on_epoch=True)\n        # FIX 4: Apply sigmoid to logits to get predictions\n        preds = (torch.sigmoid(outputs) > 0.5).int().tolist()\n        targets_list = targets.int().tolist()\n        self.val_preds.extend(preds)\n        self.val_targets.extend(targets_list)\n        \n    def on_validation_epoch_end(self):\n        if not self.val_targets: return # Avoid error on empty validation set\n        val_recall = recall_score(self.val_targets, self.val_preds, zero_division=0)\n        self.log('val_recall', val_recall, on_step=False, on_epoch=True)\n        self.val_preds.clear()\n        self.val_targets.clear()\n\n    def test_step(self, batch, batch_idx):\n        sequences, targets = batch\n        outputs = self.model(sequences)\n        # FIX 5: Apply sigmoid to logits to get predictions\n        preds = (torch.sigmoid(outputs) > 0.5).int().tolist()\n        targets_list = targets.int().tolist()\n        self.log('test_acc', accuracy_score(targets_list, preds))\n        self.log('test_prec', precision_score(targets_list, preds, zero_division=0))\n        self.log('test_recall', recall_score(targets_list, preds, zero_division=0))\n        self.log('test_f1', f1_score(targets_list, preds, zero_division=0))\n\n    def configure_optimizers(self):\n        optimizer = torch.optim.Adam(self.parameters(), lr=self.hparams.learning_rate)\n        return optimizer\n\n# --- Funes auxiliares ---\ndef create_sequences(data, target, sequence_length):\n    sequences, targets = [], []\n    user_groups = data.groupby('user_id') if 'user_id' in data.columns else [('all', data)]\n    for user_id, user_data in user_groups:\n        if len(user_data) >= sequence_length:\n            user_target = target.loc[user_data.index[0]]\n            for i in range(len(user_data) - sequence_length + 1):\n                sequence = user_data.iloc[i:i+sequence_length].drop('user_id', axis=1).values\n                sequences.append(sequence)\n                targets.append(user_target)\n    return np.array(sequences), np.array(targets)\n\ndef objective(trial, train_loader, val_loader, input_size, pos_weight):\n    hidden_layer_size = trial.suggest_int('hidden_layer_size', 64, 256, step=32)\n    num_layers = trial.suggest_int('num_layers', 1, 4)\n    dropout_rate = trial.suggest_float('dropout_rate', 0.1, 0.5)\n    learning_rate = trial.suggest_float('learning_rate', 1e-5, 1e-2, log=True)\n\n    checkpoint_callback = ModelCheckpoint(monitor='val_recall', mode='max', save_top_k=1, dirpath='optuna_checkpoints', filename='best_model')\n    pruning_callback = PyTorchLightningPruningCallback(trial, monitor=\"val_recall\")\n    early_stop_callback = EarlyStopping(monitor='val_recall', patience=15, mode='max')\n    \n    model = WazeLSTMModule(\n        input_size=input_size,\n        hidden_layer_size=hidden_layer_size,\n        num_layers=num_layers,\n        dropout_rate=dropout_rate,\n        learning_rate=learning_rate,\n        pos_weight=pos_weight\n    )\n\n    trainer = L.Trainer(\n        max_epochs=50,\n        callbacks=[checkpoint_callback, early_stop_callback, pruning_callback],\n        accelerator='auto',\n        devices=1,\n        enable_progress_bar=False,\n        logger=False\n    )\n    \n    trainer.fit(model, train_loader, val_loader)\n    return trainer.callback_metrics.get('val_recall', 0).item()\n\n# --- Funo principal de execuo ---\ndef run_pytorch_lightning_optuna_experiment(df):\n    print(\"\\n\" + \"=\"*60)\n    print(\"Iniciando experimento de otimizao de hiperparmetros com Optuna...\")\n    print(\"=\"*60)\n    \n    print(\"Preparando dados temporais para o modelo LSTM...\")\n    sequence_length = 30\n    \n    if 'user_id' not in df.columns:\n        df['user_id'] = np.repeat(np.arange(len(df) // sequence_length), sequence_length)\n    \n    feature_cols = [col for col in df.select_dtypes(include=[np.number]).columns if col not in ['label2']]\n    X = df[feature_cols].copy()\n    y = df['label2'].copy()\n\n    scaler = StandardScaler()\n    X_scaled_data = scaler.fit_transform(X.drop('user_id', axis=1))\n    X_scaled_df = pd.DataFrame(X_scaled_data, columns=[col for col in feature_cols if col != 'user_id'], index=X.index)\n    X_scaled_df['user_id'] = X['user_id']\n\n    X_sequences, y_sequences = create_sequences(X_scaled_df, y, sequence_length)\n    \n    if X_sequences.shape[0] < 2:\n        print(\"No h dados suficientes para criar as sequncias.\")\n        return None, None, None\n\n    X_train_seq, X_test_seq, y_train_seq, y_test_seq = train_test_split(X_sequences, y_sequences, test_size=0.2, random_state=42, stratify=y_sequences)\n    X_train_seq, X_val_seq, y_train_seq, y_val_seq = train_test_split(X_train_seq, y_train_seq, test_size=0.25, random_state=42, stratify=y_train_seq)\n\n    print(f\"Shape das sequncias: {X_sequences.shape}, Train: {X_train_seq.shape[0]}, Val: {X_val_seq.shape[0]}, Test: {X_test_seq.shape[0]}\")\n    \n    train_loader = DataLoader(TimeSeriesDataset(X_train_seq, y_train_seq), batch_size=64, shuffle=True)\n    val_loader = DataLoader(TimeSeriesDataset(X_val_seq, y_val_seq), batch_size=64)\n    test_loader = DataLoader(TimeSeriesDataset(X_test_seq, y_test_seq), batch_size=64)\n\n    # FIX 6: Calculate pos_weight as a scalar tensor\n    class_weights_np = compute_class_weight('balanced', classes=np.unique(y_train_seq), y=y_train_seq)\n    pos_weight = torch.tensor([class_weights_np[1] / class_weights_np[0]], dtype=torch.float32)\n\n    input_size = X_train_seq.shape[2]\n    \n    study = optuna.create_study(direction='maximize', sampler=optuna.samplers.TPESampler(seed=42))\n    study.optimize(lambda trial: objective(trial, train_loader, val_loader, input_size, pos_weight), n_trials=20)\n\n    print(\"\\nMelhores hiperparmetros encontrados:\")\n    print(study.best_params)\n\n    best_params = study.best_params\n    best_model = WazeLSTMModule(\n        input_size=input_size,\n        hidden_layer_size=best_params['hidden_layer_size'],\n        num_layers=best_params['num_layers'],\n        dropout_rate=best_params['dropout_rate'],\n        learning_rate=best_params['learning_rate'],\n        pos_weight=pos_weight\n    )\n\n    trainer = L.Trainer(max_epochs=50, accelerator='auto', devices=1, logger=CSVLogger('logs_final'))\n    print(\"\\nTreinando modelo final com os melhores hiperparmetros...\")\n    trainer.fit(best_model, train_loader, val_loader)\n\n    print(\"\\nAvaliando modelo final no conjunto de teste...\")\n    test_results = trainer.test(best_model, test_loader)\n\n    results_dict = {'optimized_threshold': test_results[0]}\n    compare_with_baseline(None, results_dict)\n\n    return best_model, results_dict, study.best_params\n\ndef compare_with_baseline(baseline_results, lstm_results):\n    print(\"=\" * 60)\n    print(\"COMPARAO LSTM (PyTorch) vs BASELINE (XGBoost)\")\n    print(\"=\" * 60)\n    baseline_precision, baseline_recall, baseline_f1, baseline_accuracy = 0.424, 0.181, 0.254, 0.811\n    lstm_metrics = lstm_results['optimized_threshold']\n    \n    # Corrected keys for accessing test results\n    precision_improvement = ((lstm_metrics['test_prec'] - baseline_precision) / baseline_precision) * 100\n    recall_improvement = ((lstm_metrics['test_recall'] - baseline_recall) / baseline_recall) * 100\n    f1_improvement = ((lstm_metrics['test_f1'] - baseline_f1) / baseline_f1) * 100\n    accuracy_improvement = ((lstm_metrics['test_acc'] - baseline_accuracy) / baseline_accuracy) * 100\n    \n    print(f\"PRECISION:\\n  Baseline (XGBoost): {baseline_precision:.3f}\\n  LSTM:               {lstm_metrics['test_prec']:.3f}\\n  Melhoria:           {precision_improvement:+.1f}%\\n\")\n    print(f\"RECALL:\\n  Baseline (XGBoost): {baseline_recall:.3f}\\n  LSTM:               {lstm_metrics['test_recall']:.3f}\\n  Melhoria:           {recall_improvement:+.1f}%\\n\")\n    print(f\"F1-SCORE:\\n  Baseline (XGBoost): {baseline_f1:.3f}\\n  LSTM:               {lstm_metrics['test_f1']:.3f}\\n  Melhoria:           {f1_improvement:+.1f}%\\n\")\n    print(f\"ACCURACY:\\n  Baseline (XGBoost): {baseline_accuracy:.3f}\\n  LSTM:               {lstm_metrics['test_acc']:.3f}\\n  Melhoria:           {accuracy_improvement:+.1f}%\\n\")\n    \n    if precision_improvement >= 250:\n        print(f\" OBJETIVO ALCANADO: {precision_improvement:.0f}% de melhoria na preciso!\")\n    else:\n        print(f\" Melhoria atual: {precision_improvement:.0f}% (objetivo: 250%)\")\n    print(\"=\" * 60)\n\n# =========================================================================\n# --- EXECUO FINAL DO PROJETO ---\n# =========================================================================\nbest_model, test_scores, best_params = run_pytorch_lightning_optuna_experiment(df)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-02T17:35:24.563350Z","iopub.execute_input":"2025-09-02T17:35:24.563741Z"}},"outputs":[{"name":"stdout","text":"Treinando modelo Random Forest...\nTreinando modelo XGBoost...\n\n============================================================\nIniciando experimento de otimizao de hiperparmetros com Optuna...\n============================================================\nPreparando dados temporais para o modelo LSTM...\n","output_type":"stream"},{"name":"stderr","text":"[I 2025-09-02 17:56:25,604] A new study created in memory with name: no-name-2ac485a8-8955-4702-8945-d58d1579235b\n","output_type":"stream"},{"name":"stdout","text":"Shape das sequncias: (11000, 30, 20), Train: 6600, Val: 2200, Test: 2200\n","output_type":"stream"},{"name":"stderr","text":"INFO: GPU available: False, used: False\nINFO: TPU available: False, using: 0 TPU cores\nINFO: HPU available: False, using: 0 HPUs\nINFO: \n  | Name      | Type              | Params | Mode \n--------------------------------------------------------\n0 | model     | WazeLSTMPredictor | 1.4 M  | train\n1 | criterion | BCEWithLogitsLoss | 0      | train\n--------------------------------------------------------\n1.4 M     Trainable params\n0         Non-trainable params\n1.4 M     Total params\n5.522     Total estimated model params size (MB)\n7         Modules in train mode\n0         Modules in eval mode\n[I 2025-09-02 18:09:17,622] Trial 0 finished with value: 0.9782016277313232 and parameters: {'hidden_layer_size': 128, 'num_layers': 4, 'dropout_rate': 0.39279757672456206, 'learning_rate': 0.0006251373574521745}. Best is trial 0 with value: 0.9782016277313232.\nINFO: GPU available: False, used: False\nINFO: TPU available: False, using: 0 TPU cores\nINFO: HPU available: False, using: 0 HPUs\nINFO: \n  | Name      | Type              | Params | Mode \n--------------------------------------------------------\n0 | model     | WazeLSTMPredictor | 113 K  | train\n1 | criterion | BCEWithLogitsLoss | 0      | train\n--------------------------------------------------------\n113 K     Trainable params\n0         Non-trainable params\n113 K     Total params\n0.455     Total estimated model params size (MB)\n7         Modules in train mode\n0         Modules in eval mode\n[I 2025-09-02 18:10:46,345] Trial 1 finished with value: 0.9509536623954773 and parameters: {'hidden_layer_size': 96, 'num_layers': 1, 'dropout_rate': 0.12323344486727979, 'learning_rate': 0.003967605077052989}. Best is trial 0 with value: 0.9782016277313232.\nINFO: GPU available: False, used: False\nINFO: TPU available: False, using: 0 TPU cores\nINFO: HPU available: False, using: 0 HPUs\nINFO: \n  | Name      | Type              | Params | Mode \n--------------------------------------------------------\n0 | model     | WazeLSTMPredictor | 2.2 M  | train\n1 | criterion | BCEWithLogitsLoss | 0      | train\n--------------------------------------------------------\n2.2 M     Trainable params\n0         Non-trainable params\n2.2 M     Total params\n8.787     Total estimated model params size (MB)\n7         Modules in train mode\n0         Modules in eval mode\n[I 2025-09-02 18:22:02,460] Trial 2 finished with value: 0.0 and parameters: {'hidden_layer_size': 192, 'num_layers': 3, 'dropout_rate': 0.10823379771832098, 'learning_rate': 0.008123245085588688}. Best is trial 0 with value: 0.9782016277313232.\nINFO: GPU available: False, used: False\nINFO: TPU available: False, using: 0 TPU cores\nINFO: HPU available: False, using: 0 HPUs\nINFO: \n  | Name      | Type              | Params | Mode \n--------------------------------------------------------\n0 | model     | WazeLSTMPredictor | 566 K  | train\n1 | criterion | BCEWithLogitsLoss | 0      | train\n--------------------------------------------------------\n566 K     Trainable params\n0         Non-trainable params\n566 K     Total params\n2.267     Total estimated model params size (MB)\n7         Modules in train mode\n0         Modules in eval mode\n[I 2025-09-02 18:24:55,553] Trial 3 finished with value: 0.6294277906417847 and parameters: {'hidden_layer_size': 224, 'num_layers': 1, 'dropout_rate': 0.17272998688284025, 'learning_rate': 3.5498788321965036e-05}. Best is trial 0 with value: 0.9782016277313232.\nINFO: GPU available: False, used: False\nINFO: TPU available: False, using: 0 TPU cores\nINFO: HPU available: False, using: 0 HPUs\nINFO: \n  | Name      | Type              | Params | Mode \n--------------------------------------------------------\n0 | model     | WazeLSTMPredictor | 985 K  | train\n1 | criterion | BCEWithLogitsLoss | 0      | train\n--------------------------------------------------------\n985 K     Trainable params\n0         Non-trainable params\n985 K     Total params\n3.941     Total estimated model params size (MB)\n7         Modules in train mode\n0         Modules in eval mode\n[I 2025-09-02 18:30:01,387] Trial 4 finished with value: 0.8092643022537231 and parameters: {'hidden_layer_size': 128, 'num_layers': 3, 'dropout_rate': 0.2727780074568463, 'learning_rate': 7.476312062252303e-05}. Best is trial 0 with value: 0.9782016277313232.\nINFO: GPU available: False, used: False\nINFO: TPU available: False, using: 0 TPU cores\nINFO: HPU available: False, using: 0 HPUs\nINFO: \n  | Name      | Type              | Params | Mode \n--------------------------------------------------------\n0 | model     | WazeLSTMPredictor | 421 K  | train\n1 | criterion | BCEWithLogitsLoss | 0      | train\n--------------------------------------------------------\n421 K     Trainable params\n0         Non-trainable params\n421 K     Total params\n1.685     Total estimated model params size (MB)\n7         Modules in train mode\n0         Modules in eval mode\n[I 2025-09-02 18:30:17,368] Trial 5 pruned. Trial was pruned at epoch 1.\nINFO: GPU available: False, used: False\nINFO: TPU available: False, using: 0 TPU cores\nINFO: HPU available: False, using: 0 HPUs\nINFO: \n  | Name      | Type              | Params | Mode \n--------------------------------------------------------\n0 | model     | WazeLSTMPredictor | 2.1 M  | train\n1 | criterion | BCEWithLogitsLoss | 0      | train\n--------------------------------------------------------\n2.1 M     Trainable params\n0         Non-trainable params\n2.1 M     Total params\n8.593     Total estimated model params size (MB)\n7         Modules in train mode\n0         Modules in eval mode\n[I 2025-09-02 18:31:43,933] Trial 6 pruned. Trial was pruned at epoch 1.\nINFO: GPU available: False, used: False\nINFO: TPU available: False, using: 0 TPU cores\nINFO: HPU available: False, using: 0 HPUs\nINFO: \n  | Name      | Type              | Params | Mode \n--------------------------------------------------------\n0 | model     | WazeLSTMPredictor | 421 K  | train\n1 | criterion | BCEWithLogitsLoss | 0      | train\n--------------------------------------------------------\n421 K     Trainable params\n0         Non-trainable params\n421 K     Total params\n1.685     Total estimated model params size (MB)\n7         Modules in train mode\n0         Modules in eval mode\n[I 2025-09-02 18:31:52,142] Trial 7 pruned. Trial was pruned at epoch 0.\nINFO: GPU available: False, used: False\nINFO: TPU available: False, using: 0 TPU cores\nINFO: HPU available: False, using: 0 HPUs\nINFO: \n  | Name      | Type              | Params | Mode \n--------------------------------------------------------\n0 | model     | WazeLSTMPredictor | 352 K  | train\n1 | criterion | BCEWithLogitsLoss | 0      | train\n--------------------------------------------------------\n352 K     Trainable params\n0         Non-trainable params\n352 K     Total params\n1.410     Total estimated model params size (MB)\n7         Modules in train mode\n0         Modules in eval mode\n[I 2025-09-02 18:32:12,885] Trial 8 pruned. Trial was pruned at epoch 1.\nINFO: GPU available: False, used: False\nINFO: TPU available: False, using: 0 TPU cores\nINFO: HPU available: False, using: 0 HPUs\nINFO: \n  | Name      | Type              | Params | Mode \n--------------------------------------------------------\n0 | model     | WazeLSTMPredictor | 194 K  | train\n1 | criterion | BCEWithLogitsLoss | 0      | train\n--------------------------------------------------------\n194 K     Trainable params\n0         Non-trainable params\n194 K     Total params\n0.779     Total estimated model params size (MB)\n7         Modules in train mode\n0         Modules in eval mode\n[I 2025-09-02 18:32:18,005] Trial 9 pruned. Trial was pruned at epoch 0.\nINFO: GPU available: False, used: False\nINFO: TPU available: False, using: 0 TPU cores\nINFO: HPU available: False, using: 0 HPUs\nINFO: \n  | Name      | Type              | Params | Mode \n--------------------------------------------------------\n0 | model     | WazeLSTMPredictor | 5.5 M  | train\n1 | criterion | BCEWithLogitsLoss | 0      | train\n--------------------------------------------------------\n5.5 M     Trainable params\n0         Non-trainable params\n5.5 M     Total params\n21.858    Total estimated model params size (MB)\n7         Modules in train mode\n0         Modules in eval mode\n[I 2025-09-02 18:35:43,938] Trial 10 pruned. Trial was pruned at epoch 1.\nINFO: GPU available: False, used: False\nINFO: TPU available: False, using: 0 TPU cores\nINFO: HPU available: False, using: 0 HPUs\nINFO: \n  | Name      | Type              | Params | Mode \n--------------------------------------------------------\n0 | model     | WazeLSTMPredictor | 153 K  | train\n1 | criterion | BCEWithLogitsLoss | 0      | train\n--------------------------------------------------------\n153 K     Trainable params\n0         Non-trainable params\n153 K     Total params\n0.615     Total estimated model params size (MB)\n7         Modules in train mode\n0         Modules in eval mode\n[I 2025-09-02 18:35:54,537] Trial 11 pruned. Trial was pruned at epoch 1.\nINFO: GPU available: False, used: False\nINFO: TPU available: False, using: 0 TPU cores\nINFO: HPU available: False, using: 0 HPUs\nINFO: \n  | Name      | Type              | Params | Mode \n--------------------------------------------------------\n0 | model     | WazeLSTMPredictor | 336 K  | train\n1 | criterion | BCEWithLogitsLoss | 0      | train\n--------------------------------------------------------\n336 K     Trainable params\n0         Non-trainable params\n336 K     Total params\n1.346     Total estimated model params size (MB)\n7         Modules in train mode\n0         Modules in eval mode\n[I 2025-09-02 18:36:02,856] Trial 12 pruned. Trial was pruned at epoch 0.\nINFO: GPU available: False, used: False\nINFO: TPU available: False, using: 0 TPU cores\nINFO: HPU available: False, using: 0 HPUs\nINFO: \n  | Name      | Type              | Params | Mode \n--------------------------------------------------------\n0 | model     | WazeLSTMPredictor | 985 K  | train\n1 | criterion | BCEWithLogitsLoss | 0      | train\n--------------------------------------------------------\n985 K     Trainable params\n0         Non-trainable params\n985 K     Total params\n3.941     Total estimated model params size (MB)\n7         Modules in train mode\n0         Modules in eval mode\n[I 2025-09-02 18:36:26,441] Trial 13 pruned. Trial was pruned at epoch 0.\nINFO: GPU available: False, used: False\nINFO: TPU available: False, using: 0 TPU cores\nINFO: HPU available: False, using: 0 HPUs\nINFO: \n  | Name      | Type              | Params | Mode \n--------------------------------------------------------\n0 | model     | WazeLSTMPredictor | 336 K  | train\n1 | criterion | BCEWithLogitsLoss | 0      | train\n--------------------------------------------------------\n336 K     Trainable params\n0         Non-trainable params\n336 K     Total params\n1.346     Total estimated model params size (MB)\n7         Modules in train mode\n0         Modules in eval mode\n[I 2025-09-02 18:36:34,726] Trial 14 pruned. Trial was pruned at epoch 0.\nINFO: GPU available: False, used: False\nINFO: TPU available: False, using: 0 TPU cores\nINFO: HPU available: False, using: 0 HPUs\nINFO: \n  | Name      | Type              | Params | Mode \n--------------------------------------------------------\n0 | model     | WazeLSTMPredictor | 559 K  | train\n1 | criterion | BCEWithLogitsLoss | 0      | train\n--------------------------------------------------------\n559 K     Trainable params\n0         Non-trainable params\n559 K     Total params\n2.237     Total estimated model params size (MB)\n7         Modules in train mode\n0         Modules in eval mode\n[I 2025-09-02 18:36:50,251] Trial 15 pruned. Trial was pruned at epoch 0.\nINFO: GPU available: False, used: False\nINFO: TPU available: False, using: 0 TPU cores\nINFO: HPU available: False, using: 0 HPUs\nINFO: \n  | Name      | Type              | Params | Mode \n--------------------------------------------------------\n0 | model     | WazeLSTMPredictor | 914 K  | train\n1 | criterion | BCEWithLogitsLoss | 0      | train\n--------------------------------------------------------\n914 K     Trainable params\n0         Non-trainable params\n914 K     Total params\n3.657     Total estimated model params size (MB)\n7         Modules in train mode\n0         Modules in eval mode\n[I 2025-09-02 18:37:09,647] Trial 16 pruned. Trial was pruned at epoch 0.\nINFO: GPU available: False, used: False\nINFO: TPU available: False, using: 0 TPU cores\nINFO: HPU available: False, using: 0 HPUs\nINFO: \n  | Name      | Type              | Params | Mode \n--------------------------------------------------------\n0 | model     | WazeLSTMPredictor | 782 K  | train\n1 | criterion | BCEWithLogitsLoss | 0      | train\n--------------------------------------------------------\n782 K     Trainable params\n0         Non-trainable params\n782 K     Total params\n3.128     Total estimated model params size (MB)\n7         Modules in train mode\n0         Modules in eval mode\n","output_type":"stream"}],"execution_count":null},{"cell_type":"markdown","source":"### **Sharing the Findings**\n\n> _ This project successfully developed and evaluated machine learning models to predict user churn at Waze. The initial baseline model, XGBoost, provided a solid performance benchmark, while a more advanced LSTM neural network, optimized through an automated framework, demonstrated a significant potential for breakthrough performance.\n\n> _ Baseline Model Performance and Trade-offs\nThe initial modeling phase focused on tree-based ensembles like Random Forest and XGBoost. These models were chosen because they generally offer superior predictive performance compared to simpler, more interpretable models like logistic regression. The champion baseline model, XGBoost, established a performance benchmark with a recall of approximately 18.1% on the test set. While functional, this level of recall was deemed insufficient for making high-stakes business decisions, suggesting its best use would be for guiding exploratory analysis.\n\n> _ Advanced Modeling with LSTMs and Automated Optimization\nTo improve upon the baseline and capture potential time-based patterns in user behavior, a more advanced Long Short-Term Memory (LSTM) neural network was implemented. Recognizing that such complex models have numerous hyperparameters that are difficult to tune manually, we employed an automated optimization framework, Optuna, to systematically find the best model configuration. This process efficiently evaluated various model architectures and utilized an intelligent pruning strategy, automatically stopping unpromising trials early to save computational resources.\n\n> _ Key Result: A Breakthrough in Predictive Power\nThe automated search discovered an LSTM model configuration that achieved a validation recall of 97.8%. This represents a potential 440% improvement over the XGBoost baseline's recall score, demonstrating the profound impact of using a sequential model with optimized hyperparameters for predicting user churn. This result directly challenges the initial conclusion; a model with such high recall is a strong candidate for being integrated into business operations to proactively reduce churn.\n\n> _ Recommendations for Model Enhancement\nTo further enhance this model, future work should focus on two key areas. Firstly, feature engineering, which was highly effective in this project, could be expanded with more domain knowledge to create better predictive signals. Secondly, the model could be significantly improved by incorporating more granular data, such as drive-level information (times, locations), user interaction data (e.g., hazard reporting frequency), and unique start/end location counts.\n\n> _ Methodological Note\nThe project's robust methodology involved splitting the data into training, validation, and test sets. This ensures that the final performance metrics, gathered from the unseen test set, are a reliable estimate of how the model would perform on new, real-world data.\n\n\n\n> _The recommendentions on the model will depends on the intended use of the model. If the model is meant to inform significant business decisions, then no, it is not reliable enough due to its poor recall score. However, if the model is intended to guide further exploratory analysis, it could still be valuable.._\n\n> _Splitting the data into training, validation, and test sets results in the data into three sets results in less data available for training the model compared to a two-way split. However, using a separate validation set for model selection allows for testing the champion model solely on the test set, providing a more accurate estimate of future performance than splitting the data two ways and choosing the champion model based on test data performance.._\n\n> _The advantage of using a logistic regression model instead of an ensemble of tree-based models  for classification tasks lies in its interpretability. Logistic regression models are easier to understand because they assign coefficients to predictor variables. This not only shows which features are most influential in the final predictions but also indicates whether each feature is positively or negatively correlated with the target variable._\n\n> _The advantage of using an ensemble of tree-based models like random forest or XGBoost over a logistic regression model for classification tasks is that tree-based model ensembles often provide better predictive performance. If the primary goal is to maximize the model's predictive power, tree-based models typically outperform logistic regression (though not always!). Additionally, they require less data cleaning and make fewer assumptions about the distributions of predictor variables, making them easier to work with.._\n\n> _To enhance this model, new features could be engineered to provide better predictive signals, especially if domain knowledge is applied. For this model, engineered features accounted for over half of the top 10 most predictive features. Additionally, reconstructing the model with different combinations of predictor variables could help reduce noise from less predictive features.._\n\n> _It would be an additional helpful feature to have drive-level information for each user (such as drive times, geographic locations, etc.) for improve the model. It would probably also be helpful to have more granular data to know how users interact with the app. For example, how often do they report or confirm road hazard alerts? Finally, it could be helpful to know the monthly count of unique starting and ending locations each driver inputs._\n","metadata":{}}]}